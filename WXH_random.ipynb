{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e66e88c-296d-4309-a25c-c939274801b7",
   "metadata": {},
   "source": [
    "## base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56230e4-9293-474a-a2f3-5ec157771c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import shap\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('DATA.csv')\n",
    "\n",
    "# Define feature columns - Baseline model (only technical indicators)\n",
    "continuous_features = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct', 'J', \n",
    "                      'mfi', 'MACD', 'MACD_diff',  'BB_rel_pos', 'Vol_Change']\n",
    "binary_features = ['MA5_GT_MA20']\n",
    "features = continuous_features + binary_features\n",
    "\n",
    "# Split data by company in chronological order\n",
    "train_data_list = []\n",
    "val_data_list = []\n",
    "test_data_list = []\n",
    "\n",
    "for company in df['Company'].unique():\n",
    "    company_data = df[df['Company'] == company].copy()\n",
    "    company_data = company_data.sort_values('Date')  \n",
    "    \n",
    "    n_company = len(company_data)\n",
    "    train_size = int(0.7 * n_company)\n",
    "    val_size = int(0.15 * n_company)\n",
    "    \n",
    "    train_data_list.append(company_data.iloc[:train_size])\n",
    "    val_data_list.append(company_data.iloc[train_size:train_size+val_size])\n",
    "    test_data_list.append(company_data.iloc[train_size+val_size:])\n",
    "\n",
    "# Concatenate all companies' data\n",
    "train_data = pd.concat(train_data_list, ignore_index=True)\n",
    "val_data = pd.concat(val_data_list, ignore_index=True)\n",
    "test_data = pd.concat(test_data_list, ignore_index=True)\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")\n",
    "print(f\"Training set company distribution:\\n{train_data['Company'].value_counts().sort_index()}\")\n",
    "print(f\"Test set company distribution:\\n{test_data['Company'].value_counts().sort_index()}\")\n",
    "\n",
    "# Modified preprocessing function\n",
    "def preprocess_data(train_df, val_df, test_df, target_col, continuous_features, binary_features):\n",
    "    all_features = continuous_features + binary_features\n",
    "    \n",
    "    # Drop missing values\n",
    "    train_df = train_df.dropna(subset=all_features + [target_col])\n",
    "    val_df = val_df.dropna(subset=all_features + [target_col])\n",
    "    test_df = test_df.dropna(subset=all_features + [target_col])\n",
    "    \n",
    "    # Separate continuous and binary features\n",
    "    X_train_continuous = train_df[continuous_features]\n",
    "    X_val_continuous = val_df[continuous_features]\n",
    "    X_test_continuous = test_df[continuous_features]\n",
    "    \n",
    "    X_train_binary = train_df[binary_features]\n",
    "    X_val_binary = val_df[binary_features]\n",
    "    X_test_binary = test_df[binary_features]\n",
    "    \n",
    "    y_train = train_df[target_col]\n",
    "    y_val = val_df[target_col]\n",
    "    y_test = test_df[target_col]\n",
    "    \n",
    "    # Standardize only continuous features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_continuous_scaled = scaler.fit_transform(X_train_continuous)\n",
    "    X_val_continuous_scaled = scaler.transform(X_val_continuous)\n",
    "    X_test_continuous_scaled = scaler.transform(X_test_continuous)\n",
    "    \n",
    "    # Combine scaled continuous features with unscaled binary features\n",
    "    X_train_scaled = np.hstack([X_train_continuous_scaled, X_train_binary.values])\n",
    "    X_val_scaled = np.hstack([X_val_continuous_scaled, X_val_binary.values])\n",
    "    X_test_scaled = np.hstack([X_test_continuous_scaled, X_test_binary.values])\n",
    "    \n",
    "    return X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, scaler\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(y_true, y_pred, y_prob, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Overall metrics\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    # Class-specific metrics\n",
    "    precision_per_class = precision_score(y_true, y_pred, average=None)\n",
    "    recall_per_class = recall_score(y_true, y_pred, average=None)\n",
    "    f1_per_class = f1_score(y_true, y_pred, average=None)\n",
    "    \n",
    "    # Confusion matrix heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance metrics table\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.axis('tight')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    table_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Macro F1 Score', f'{f1_macro:.4f}'],\n",
    "        ['Overall Accuracy', f'{accuracy:.4f}'],\n",
    "        ['AUC', f'{auc:.4f}'],\n",
    "        ['', ''],  # Empty row for separation\n",
    "        ['Class 1 Precision', f'{precision_per_class[1]:.4f}'],\n",
    "        ['Class 1 Recall', f'{recall_per_class[1]:.4f}'],\n",
    "        ['Class 1 F1', f'{f1_per_class[1]:.4f}'],\n",
    "        ['', ''],  # Empty row for separation\n",
    "        ['Class 0 Precision', f'{precision_per_class[0]:.4f}'],\n",
    "        ['Class 0 Recall', f'{recall_per_class[0]:.4f}'],\n",
    "        ['Class 0 F1', f'{f1_per_class[0]:.4f}']\n",
    "    ]\n",
    "    \n",
    "    table = plt.table(cellText=table_data[1:], colLabels=table_data[0],\n",
    "                     cellLoc='center', loc='center',\n",
    "                     colWidths=[0.4, 0.3])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.5, 2)\n",
    "    \n",
    "    # Set table style\n",
    "    for i in range(len(table_data)):\n",
    "        for j in range(len(table_data[0])):\n",
    "            cell = table[(i, j)]\n",
    "            if i == 0:  # header\n",
    "                cell.set_facecolor('#4CAF50')\n",
    "                cell.set_text_props(weight='bold', color='white')\n",
    "            elif len(table_data[i]) > 0 and table_data[i][0] == '':  # empty rows\n",
    "                cell.set_facecolor('#ffffff')\n",
    "                cell.set_text_props(color='white')\n",
    "            else:\n",
    "                cell.set_facecolor('#f0f0f0')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return {'confusion_matrix': cm, 'f1_macro': f1_macro, 'accuracy': accuracy, 'auc': auc,\n",
    "            'class_0_precision': precision_per_class[0], 'class_0_recall': recall_per_class[0], 'class_0_f1': f1_per_class[0],\n",
    "            'class_1_precision': precision_per_class[1], 'class_1_recall': recall_per_class[1], 'class_1_f1': f1_per_class[1]}\n",
    "\n",
    "# 1D_Up prediction\n",
    "print(\"=\" * 60)\n",
    "print(\"1D_Up Prediction Model - Random Forest Baseline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "X_train_1d, y_train_1d, X_val_1d, y_val_1d, X_test_1d, y_test_1d, scaler_1d = preprocess_data(\n",
    "    train_data, val_data, test_data, '1D_Up', continuous_features, binary_features)\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 400, 500], \n",
    "    'max_depth': [ 6, 8,10, None],    \n",
    "    'min_samples_split': [2, 5, 8], \n",
    "    'min_samples_leaf': [1, 2, 3],  \n",
    "    'max_features': ['sqrt', 'log2'] \n",
    "}\n",
    "\n",
    "print(\"Starting hyperparameter tuning for 1D model...\")\n",
    "grid_search_1d = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1,class_weight='balanced'),\n",
    "    param_grid, cv=tscv, scoring='f1', n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "grid_search_1d.fit(X_train_1d, y_train_1d)\n",
    "best_params_1d = grid_search_1d.best_params_\n",
    "print(f\"Best parameters for 1D model: {best_params_1d}\")\n",
    "print(f\"Best cross-validation F1 score: {grid_search_1d.best_score_:.4f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "final_model_1d = RandomForestClassifier(**best_params_1d, random_state=42, n_jobs=-1,class_weight='balanced')\n",
    "final_model_1d.fit(X_train_1d, y_train_1d)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_1d = final_model_1d.predict(X_test_1d)\n",
    "y_prob_1d = final_model_1d.predict_proba(X_test_1d)[:, 1]\n",
    "\n",
    "print(\"\\n1D Model Test Set Results:\")\n",
    "results_1d = evaluate_model(y_test_1d, y_pred_1d, y_prob_1d, \"1D_Up Prediction\")\n",
    "\n",
    "# 20D_Up prediction\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"20D_Up Prediction Model - Random Forest Baseline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "X_train_20d, y_train_20d, X_val_20d, y_val_20d, X_test_20d, y_test_20d, scaler_20d = preprocess_data(\n",
    "    train_data, val_data, test_data, '20D_Up', continuous_features, binary_features)\n",
    "\n",
    "print(\"Starting hyperparameter tuning for 20D model...\")\n",
    "grid_search_20d = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1,class_weight='balanced'),\n",
    "    param_grid, cv=tscv, scoring='f1', n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "grid_search_20d.fit(X_train_20d, y_train_20d)\n",
    "best_params_20d = grid_search_20d.best_params_\n",
    "print(f\"Best parameters for 20D model: {best_params_20d}\")\n",
    "print(f\"Best cross-validation F1 score: {grid_search_20d.best_score_:.4f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "final_model_20d = RandomForestClassifier(**best_params_20d, random_state=42, n_jobs=-1,class_weight='balanced')\n",
    "final_model_20d.fit(X_train_20d, y_train_20d)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_20d = final_model_20d.predict(X_test_20d)\n",
    "y_prob_20d = final_model_20d.predict_proba(X_test_20d)[:, 1]\n",
    "\n",
    "print(\"\\n20D Model Test Set Results:\")\n",
    "results_20d = evaluate_model(y_test_20d, y_pred_20d, y_prob_20d, \"20D_Up Prediction\")\n",
    "\n",
    "# SHAP Feature Importance Analysis\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SHAP Feature Importance Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = continuous_features + binary_features\n",
    "feature_names_array = np.array(feature_names)\n",
    "\n",
    "# Create SHAP explainers for both models\n",
    "print(\"Creating SHAP explainers...\")\n",
    "explainer_1d = shap.Explainer(final_model_1d, X_train_1d)\n",
    "explainer_20d = shap.Explainer(final_model_20d, X_train_20d)\n",
    "\n",
    "# Calculate SHAP values for test sets\n",
    "print(\"Calculating SHAP values for 1D model...\")\n",
    "shap_values_1d = explainer_1d(X_test_1d)\n",
    "\n",
    "print(\"Calculating SHAP values for 20D model...\")\n",
    "shap_values_20d = explainer_20d(X_test_20d)\n",
    "\n",
    "# 1D Model SHAP Analysis\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"1D_Up Model SHAP Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Summary plot for 1D model - use only positive class SHAP values\n",
    "if len(shap_values_1d.values.shape) == 3:\n",
    "    # Multi-class case - use positive class (class 1)\n",
    "    shap_vals_1d = shap_values_1d.values[:, :, 1]\n",
    "else:\n",
    "    # Binary case - use all values\n",
    "    shap_vals_1d = shap_values_1d.values\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_vals_1d, X_test_1d, feature_names=feature_names_array, show=False)\n",
    "plt.title('SHAP Summary Plot - 1D_Up Prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Waterfall plot for a single sample (1D model)\n",
    "plt.figure(figsize=(10, 6))\n",
    "if len(shap_values_1d.values.shape) == 3:\n",
    "    # For multi-class, create a new Explanation object for single class\n",
    "    sample_explanation = shap.Explanation(\n",
    "        values=shap_values_1d.values[0, :, 1],\n",
    "        base_values=shap_values_1d.base_values[0, 1] if hasattr(shap_values_1d.base_values, 'shape') and len(shap_values_1d.base_values.shape) > 1 else shap_values_1d.base_values[0],\n",
    "        data=shap_values_1d.data[0],\n",
    "        feature_names=feature_names_array\n",
    "    )\n",
    "else:\n",
    "    sample_explanation = shap_values_1d[0]\n",
    "\n",
    "shap.waterfall_plot(sample_explanation, show=False)\n",
    "plt.title('SHAP Waterfall Plot - Single Sample (1D_Up Prediction)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance ranking table for 1D model\n",
    "if len(shap_values_1d.values.shape) == 3:\n",
    "    mean_shap_1d = np.mean(shap_values_1d.values[:, :, 1], axis=0)\n",
    "    abs_mean_shap_1d = np.mean(np.abs(shap_values_1d.values[:, :, 1]), axis=0)\n",
    "else:\n",
    "    mean_shap_1d = np.mean(shap_values_1d.values, axis=0)\n",
    "    abs_mean_shap_1d = np.mean(np.abs(shap_values_1d.values), axis=0)\n",
    "\n",
    "importance_df_1d = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Mean_SHAP': mean_shap_1d,\n",
    "    'Abs_Mean_SHAP': abs_mean_shap_1d\n",
    "}).sort_values('Abs_Mean_SHAP', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance Ranking for 1D_Up Prediction (sorted by absolute value, preserving direction):\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"{'Rank':<4} {'Feature':<20} {'Mean SHAP':<12} {'|Mean SHAP|':<12} {'Direction':<12}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for i, (_, row) in enumerate(importance_df_1d.iterrows(), 1):\n",
    "    direction = \"↑ Positive\" if row['Mean_SHAP'] > 0 else \"↓ Negative\"\n",
    "    print(f\"{i:>2}. {row['Feature']:<20} {row['Mean_SHAP']:>+9.6f} {row['Abs_Mean_SHAP']:>11.6f} {direction}\")\n",
    "\n",
    "# 20D Model SHAP Analysis\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"20D_Up Model SHAP Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Summary plot for 20D model - use only positive class SHAP values\n",
    "if len(shap_values_20d.values.shape) == 3:\n",
    "    # Multi-class case - use positive class (class 1)\n",
    "    shap_vals_20d = shap_values_20d.values[:, :, 1]\n",
    "else:\n",
    "    # Binary case - use all values\n",
    "    shap_vals_20d = shap_values_20d.values\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_vals_20d, X_test_20d, feature_names=feature_names_array, show=False)\n",
    "plt.title('SHAP Summary Plot - 20D_Up Prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Waterfall plot for a single sample (20D model)\n",
    "plt.figure(figsize=(10, 6))\n",
    "if len(shap_values_20d.values.shape) == 3:\n",
    "    # For multi-class, create a new Explanation object for single class\n",
    "    sample_explanation = shap.Explanation(\n",
    "        values=shap_values_20d.values[0, :, 1],\n",
    "        base_values=shap_values_20d.base_values[0, 1] if hasattr(shap_values_20d.base_values, 'shape') and len(shap_values_20d.base_values.shape) > 1 else shap_values_20d.base_values[0],\n",
    "        data=shap_values_20d.data[0],\n",
    "        feature_names=feature_names_array\n",
    "    )\n",
    "else:\n",
    "    sample_explanation = shap_values_20d[0]\n",
    "\n",
    "shap.waterfall_plot(sample_explanation, show=False)\n",
    "plt.title('SHAP Waterfall Plot - Single Sample (20D_Up Prediction)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance ranking table for 20D model\n",
    "if len(shap_values_20d.values.shape) == 3:\n",
    "    mean_shap_20d = np.mean(shap_values_20d.values[:, :, 1], axis=0)\n",
    "    abs_mean_shap_20d = np.mean(np.abs(shap_values_20d.values[:, :, 1]), axis=0)\n",
    "else:\n",
    "    mean_shap_20d = np.mean(shap_values_20d.values, axis=0)\n",
    "    abs_mean_shap_20d = np.mean(np.abs(shap_values_20d.values), axis=0)\n",
    "\n",
    "importance_df_20d = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Mean_SHAP': mean_shap_20d,\n",
    "    'Abs_Mean_SHAP': abs_mean_shap_20d\n",
    "}).sort_values('Abs_Mean_SHAP', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance Ranking for 20D_Up Prediction (sorted by absolute value, preserving direction):\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"{'Rank':<4} {'Feature':<20} {'Mean SHAP':<12} {'|Mean SHAP|':<12} {'Direction':<12}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for i, (_, row) in enumerate(importance_df_20d.iterrows(), 1):\n",
    "    direction = \"↑ Positive\" if row['Mean_SHAP'] > 0 else \"↓ Negative\"\n",
    "    print(f\"{i:>2}. {row['Feature']:<20} {row['Mean_SHAP']:>+9.6f} {row['Abs_Mean_SHAP']:>11.6f} {direction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c54250-ce8b-4799-a5a2-4fdd90064936",
   "metadata": {},
   "source": [
    "## interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6953768-9e9a-477b-b6e4-8f1a69849453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import shap\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('DATA.csv')\n",
    "\n",
    "# Define feature columns \n",
    "continuous_features = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct', 'J', \n",
    "                      'mfi', 'MACD', 'MACD_diff',  'BB_rel_pos', 'Vol_Change',\"Interest_Rate\"]\n",
    "binary_features = ['MA5_GT_MA20']\n",
    "features = continuous_features + binary_features\n",
    "\n",
    "# Split data by company in chronological order\n",
    "train_data_list = []\n",
    "val_data_list = []\n",
    "test_data_list = []\n",
    "\n",
    "for company in df['Company'].unique():\n",
    "    company_data = df[df['Company'] == company].copy()\n",
    "    company_data = company_data.sort_values('Date') \n",
    "    \n",
    "    n_company = len(company_data)\n",
    "    train_size = int(0.7 * n_company)\n",
    "    val_size = int(0.15 * n_company)\n",
    "    \n",
    "    train_data_list.append(company_data.iloc[:train_size])\n",
    "    val_data_list.append(company_data.iloc[train_size:train_size+val_size])\n",
    "    test_data_list.append(company_data.iloc[train_size+val_size:])\n",
    "\n",
    "# Concatenate all companies' data\n",
    "train_data = pd.concat(train_data_list, ignore_index=True)\n",
    "val_data = pd.concat(val_data_list, ignore_index=True)\n",
    "test_data = pd.concat(test_data_list, ignore_index=True)\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")\n",
    "print(f\"Training set company distribution:\\n{train_data['Company'].value_counts().sort_index()}\")\n",
    "print(f\"Test set company distribution:\\n{test_data['Company'].value_counts().sort_index()}\")\n",
    "\n",
    "# Modified preprocessing function\n",
    "def preprocess_data(train_df, val_df, test_df, target_col, continuous_features, binary_features):\n",
    "    all_features = continuous_features + binary_features\n",
    "    \n",
    "    # Drop missing values\n",
    "    train_df = train_df.dropna(subset=all_features + [target_col])\n",
    "    val_df = val_df.dropna(subset=all_features + [target_col])\n",
    "    test_df = test_df.dropna(subset=all_features + [target_col])\n",
    "    \n",
    "    # Separate continuous and binary features\n",
    "    X_train_continuous = train_df[continuous_features]\n",
    "    X_val_continuous = val_df[continuous_features]\n",
    "    X_test_continuous = test_df[continuous_features]\n",
    "    \n",
    "    X_train_binary = train_df[binary_features]\n",
    "    X_val_binary = val_df[binary_features]\n",
    "    X_test_binary = test_df[binary_features]\n",
    "    \n",
    "    y_train = train_df[target_col]\n",
    "    y_val = val_df[target_col]\n",
    "    y_test = test_df[target_col]\n",
    "    \n",
    "    # Standardize only continuous features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_continuous_scaled = scaler.fit_transform(X_train_continuous)\n",
    "    X_val_continuous_scaled = scaler.transform(X_val_continuous)\n",
    "    X_test_continuous_scaled = scaler.transform(X_test_continuous)\n",
    "    \n",
    "    # Combine scaled continuous features with unscaled binary features\n",
    "    X_train_scaled = np.hstack([X_train_continuous_scaled, X_train_binary.values])\n",
    "    X_val_scaled = np.hstack([X_val_continuous_scaled, X_val_binary.values])\n",
    "    X_test_scaled = np.hstack([X_test_continuous_scaled, X_test_binary.values])\n",
    "    \n",
    "    return X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, scaler\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(y_true, y_pred, y_prob, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Overall metrics\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    # Class-specific metrics\n",
    "    precision_per_class = precision_score(y_true, y_pred, average=None)\n",
    "    recall_per_class = recall_score(y_true, y_pred, average=None)\n",
    "    f1_per_class = f1_score(y_true, y_pred, average=None)\n",
    "    \n",
    "    # Confusion matrix heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance metrics table\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.axis('tight')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    table_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Macro F1 Score', f'{f1_macro:.4f}'],\n",
    "        ['Overall Accuracy', f'{accuracy:.4f}'],\n",
    "        ['AUC', f'{auc:.4f}'],\n",
    "        ['', ''],  # Empty row for separation\n",
    "        ['Class 1 Precision', f'{precision_per_class[1]:.4f}'],\n",
    "        ['Class 1 Recall', f'{recall_per_class[1]:.4f}'],\n",
    "        ['Class 1 F1', f'{f1_per_class[1]:.4f}'],\n",
    "        ['', ''],  # Empty row for separation\n",
    "        ['Class 0 Precision', f'{precision_per_class[0]:.4f}'],\n",
    "        ['Class 0 Recall', f'{recall_per_class[0]:.4f}'],\n",
    "        ['Class 0 F1', f'{f1_per_class[0]:.4f}']\n",
    "    ]\n",
    "    \n",
    "    table = plt.table(cellText=table_data[1:], colLabels=table_data[0],\n",
    "                     cellLoc='center', loc='center',\n",
    "                     colWidths=[0.4, 0.3])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.5, 2)\n",
    "    \n",
    "    # Set table style\n",
    "    for i in range(len(table_data)):\n",
    "        for j in range(len(table_data[0])):\n",
    "            cell = table[(i, j)]\n",
    "            if i == 0:  # header\n",
    "                cell.set_facecolor('#4CAF50')\n",
    "                cell.set_text_props(weight='bold', color='white')\n",
    "            elif len(table_data[i]) > 0 and table_data[i][0] == '':  # empty rows\n",
    "                cell.set_facecolor('#ffffff')\n",
    "                cell.set_text_props(color='white')\n",
    "            else:\n",
    "                cell.set_facecolor('#f0f0f0')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return {'confusion_matrix': cm, 'f1_macro': f1_macro, 'accuracy': accuracy, 'auc': auc,\n",
    "            'class_0_precision': precision_per_class[0], 'class_0_recall': recall_per_class[0], 'class_0_f1': f1_per_class[0],\n",
    "            'class_1_precision': precision_per_class[1], 'class_1_recall': recall_per_class[1], 'class_1_f1': f1_per_class[1]}\n",
    "\n",
    "# 1D_Up prediction\n",
    "print(\"=\" * 60)\n",
    "print(\"1D_Up Prediction Model - Random Forest Baseline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "X_train_1d, y_train_1d, X_val_1d, y_val_1d, X_test_1d, y_test_1d, scaler_1d = preprocess_data(\n",
    "    train_data, val_data, test_data, '1D_Up', continuous_features, binary_features)\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 400, 500], \n",
    "    'max_depth': [ 6, 8,10, None],    \n",
    "    'min_samples_split': [2, 5, 8], \n",
    "    'min_samples_leaf': [1, 2, 3],  \n",
    "    'max_features': ['sqrt', 'log2'] \n",
    "}\n",
    "\n",
    "print(\"Starting hyperparameter tuning for 1D model...\")\n",
    "grid_search_1d = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1,class_weight='balanced'),\n",
    "    param_grid, cv=tscv, scoring='f1', n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "grid_search_1d.fit(X_train_1d, y_train_1d)\n",
    "best_params_1d = grid_search_1d.best_params_\n",
    "print(f\"Best parameters for 1D model: {best_params_1d}\")\n",
    "print(f\"Best cross-validation F1 score: {grid_search_1d.best_score_:.4f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "final_model_1d = RandomForestClassifier(**best_params_1d, random_state=42, n_jobs=-1,class_weight='balanced')\n",
    "final_model_1d.fit(X_train_1d, y_train_1d)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_1d = final_model_1d.predict(X_test_1d)\n",
    "y_prob_1d = final_model_1d.predict_proba(X_test_1d)[:, 1]\n",
    "\n",
    "print(\"\\n1D Model Test Set Results:\")\n",
    "results_1d = evaluate_model(y_test_1d, y_pred_1d, y_prob_1d, \"1D_Up Prediction\")\n",
    "\n",
    "# 20D_Up prediction\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"20D_Up Prediction Model - Random Forest Baseline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "X_train_20d, y_train_20d, X_val_20d, y_val_20d, X_test_20d, y_test_20d, scaler_20d = preprocess_data(\n",
    "    train_data, val_data, test_data, '20D_Up', continuous_features, binary_features)\n",
    "\n",
    "print(\"Starting hyperparameter tuning for 20D model...\")\n",
    "grid_search_20d = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1,class_weight='balanced'),\n",
    "    param_grid, cv=tscv, scoring='f1', n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "grid_search_20d.fit(X_train_20d, y_train_20d)\n",
    "best_params_20d = grid_search_20d.best_params_\n",
    "print(f\"Best parameters for 20D model: {best_params_20d}\")\n",
    "print(f\"Best cross-validation F1 score: {grid_search_20d.best_score_:.4f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "final_model_20d = RandomForestClassifier(**best_params_20d, random_state=42, n_jobs=-1,class_weight='balanced')\n",
    "final_model_20d.fit(X_train_20d, y_train_20d)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_20d = final_model_20d.predict(X_test_20d)\n",
    "y_prob_20d = final_model_20d.predict_proba(X_test_20d)[:, 1]\n",
    "\n",
    "print(\"\\n20D Model Test Set Results:\")\n",
    "results_20d = evaluate_model(y_test_20d, y_pred_20d, y_prob_20d, \"20D_Up Prediction\")\n",
    "\n",
    "# SHAP Feature Importance Analysis\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SHAP Feature Importance Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = continuous_features + binary_features\n",
    "feature_names_array = np.array(feature_names)\n",
    "\n",
    "# Create SHAP explainers for both models\n",
    "print(\"Creating SHAP explainers...\")\n",
    "explainer_1d = shap.Explainer(final_model_1d, X_train_1d)\n",
    "explainer_20d = shap.Explainer(final_model_20d, X_train_20d)\n",
    "\n",
    "# Calculate SHAP values for test sets\n",
    "print(\"Calculating SHAP values for 1D model...\")\n",
    "shap_values_1d = explainer_1d(X_test_1d,check_additivity=False)\n",
    "\n",
    "print(\"Calculating SHAP values for 20D model...\")\n",
    "shap_values_20d = explainer_20d(X_test_20d,check_additivity=False)\n",
    "\n",
    "# 1D Model SHAP Analysis\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"1D_Up Model SHAP Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Summary plot for 1D model - use only positive class SHAP values\n",
    "if len(shap_values_1d.values.shape) == 3:\n",
    "    # Multi-class case - use positive class (class 1)\n",
    "    shap_vals_1d = shap_values_1d.values[:, :, 1]\n",
    "else:\n",
    "    # Binary case - use all values\n",
    "    shap_vals_1d = shap_values_1d.values\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_vals_1d, X_test_1d, feature_names=feature_names_array, show=False)\n",
    "plt.title('SHAP Summary Plot - 1D_Up Prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Waterfall plot for a single sample (1D model)\n",
    "plt.figure(figsize=(10, 6))\n",
    "if len(shap_values_1d.values.shape) == 3:\n",
    "    # For multi-class, create a new Explanation object for single class\n",
    "    sample_explanation = shap.Explanation(\n",
    "        values=shap_values_1d.values[0, :, 1],\n",
    "        base_values=shap_values_1d.base_values[0, 1] if hasattr(shap_values_1d.base_values, 'shape') and len(shap_values_1d.base_values.shape) > 1 else shap_values_1d.base_values[0],\n",
    "        data=shap_values_1d.data[0],\n",
    "        feature_names=feature_names_array\n",
    "    )\n",
    "else:\n",
    "    sample_explanation = shap_values_1d[0]\n",
    "\n",
    "shap.waterfall_plot(sample_explanation, show=False)\n",
    "plt.title('SHAP Waterfall Plot - Single Sample (1D_Up Prediction)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance ranking table for 1D model\n",
    "if len(shap_values_1d.values.shape) == 3:\n",
    "    mean_shap_1d = np.mean(shap_values_1d.values[:, :, 1], axis=0)\n",
    "    abs_mean_shap_1d = np.mean(np.abs(shap_values_1d.values[:, :, 1]), axis=0)\n",
    "else:\n",
    "    mean_shap_1d = np.mean(shap_values_1d.values, axis=0)\n",
    "    abs_mean_shap_1d = np.mean(np.abs(shap_values_1d.values), axis=0)\n",
    "\n",
    "importance_df_1d = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Mean_SHAP': mean_shap_1d,\n",
    "    'Abs_Mean_SHAP': abs_mean_shap_1d\n",
    "}).sort_values('Abs_Mean_SHAP', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance Ranking for 1D_Up Prediction (sorted by absolute value, preserving direction):\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"{'Rank':<4} {'Feature':<20} {'Mean SHAP':<12} {'|Mean SHAP|':<12} {'Direction':<12}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for i, (_, row) in enumerate(importance_df_1d.iterrows(), 1):\n",
    "    direction = \"↑ Positive\" if row['Mean_SHAP'] > 0 else \"↓ Negative\"\n",
    "    print(f\"{i:>2}. {row['Feature']:<20} {row['Mean_SHAP']:>+9.6f} {row['Abs_Mean_SHAP']:>11.6f} {direction}\")\n",
    "\n",
    "# 20D Model SHAP Analysis\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"20D_Up Model SHAP Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Summary plot for 20D model - use only positive class SHAP values\n",
    "if len(shap_values_20d.values.shape) == 3:\n",
    "    # Multi-class case - use positive class (class 1)\n",
    "    shap_vals_20d = shap_values_20d.values[:, :, 1]\n",
    "else:\n",
    "    # Binary case - use all values\n",
    "    shap_vals_20d = shap_values_20d.values\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_vals_20d, X_test_20d, feature_names=feature_names_array, show=False)\n",
    "plt.title('SHAP Summary Plot - 20D_Up Prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Waterfall plot for a single sample (20D model)\n",
    "plt.figure(figsize=(10, 6))\n",
    "if len(shap_values_20d.values.shape) == 3:\n",
    "    # For multi-class, create a new Explanation object for single class\n",
    "    sample_explanation = shap.Explanation(\n",
    "        values=shap_values_20d.values[0, :, 1],\n",
    "        base_values=shap_values_20d.base_values[0, 1] if hasattr(shap_values_20d.base_values, 'shape') and len(shap_values_20d.base_values.shape) > 1 else shap_values_20d.base_values[0],\n",
    "        data=shap_values_20d.data[0],\n",
    "        feature_names=feature_names_array\n",
    "    )\n",
    "else:\n",
    "    sample_explanation = shap_values_20d[0]\n",
    "\n",
    "shap.waterfall_plot(sample_explanation, show=False)\n",
    "plt.title('SHAP Waterfall Plot - Single Sample (20D_Up Prediction)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance ranking table for 20D model\n",
    "if len(shap_values_20d.values.shape) == 3:\n",
    "    mean_shap_20d = np.mean(shap_values_20d.values[:, :, 1], axis=0)\n",
    "    abs_mean_shap_20d = np.mean(np.abs(shap_values_20d.values[:, :, 1]), axis=0)\n",
    "else:\n",
    "    mean_shap_20d = np.mean(shap_values_20d.values, axis=0)\n",
    "    abs_mean_shap_20d = np.mean(np.abs(shap_values_20d.values), axis=0)\n",
    "\n",
    "importance_df_20d = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Mean_SHAP': mean_shap_20d,\n",
    "    'Abs_Mean_SHAP': abs_mean_shap_20d\n",
    "}).sort_values('Abs_Mean_SHAP', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance Ranking for 20D_Up Prediction (sorted by absolute value, preserving direction):\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"{'Rank':<4} {'Feature':<20} {'Mean SHAP':<12} {'|Mean SHAP|':<12} {'Direction':<12}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for i, (_, row) in enumerate(importance_df_20d.iterrows(), 1):\n",
    "    direction = \"↑ Positive\" if row['Mean_SHAP'] > 0 else \"↓ Negative\"\n",
    "    print(f\"{i:>2}. {row['Feature']:<20} {row['Mean_SHAP']:>+9.6f} {row['Abs_Mean_SHAP']:>11.6f} {direction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fe2edd-a29a-4737-91eb-235789082c0c",
   "metadata": {},
   "source": [
    "## BTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c4806-af03-4632-a36e-6cbc24dbb8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import shap\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('DATA.csv')\n",
    "\n",
    "# Define feature columns \n",
    "continuous_features = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct', 'J', \n",
    "                      'mfi', 'MACD', 'MACD_diff',  'BB_rel_pos', 'Vol_Change',\"Bitcoin_Close\"]\n",
    "binary_features = ['MA5_GT_MA20']\n",
    "features = continuous_features + binary_features\n",
    "\n",
    "# Split data by company in chronological order\n",
    "train_data_list = []\n",
    "val_data_list = []\n",
    "test_data_list = []\n",
    "\n",
    "for company in df['Company'].unique():\n",
    "    company_data = df[df['Company'] == company].copy()\n",
    "    company_data = company_data.sort_values('Date')  \n",
    "    \n",
    "    n_company = len(company_data)\n",
    "    train_size = int(0.7 * n_company)\n",
    "    val_size = int(0.15 * n_company)\n",
    "    \n",
    "    train_data_list.append(company_data.iloc[:train_size])\n",
    "    val_data_list.append(company_data.iloc[train_size:train_size+val_size])\n",
    "    test_data_list.append(company_data.iloc[train_size+val_size:])\n",
    "\n",
    "# Concatenate all companies' data\n",
    "train_data = pd.concat(train_data_list, ignore_index=True)\n",
    "val_data = pd.concat(val_data_list, ignore_index=True)\n",
    "test_data = pd.concat(test_data_list, ignore_index=True)\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")\n",
    "print(f\"Training set company distribution:\\n{train_data['Company'].value_counts().sort_index()}\")\n",
    "print(f\"Test set company distribution:\\n{test_data['Company'].value_counts().sort_index()}\")\n",
    "\n",
    "# Modified preprocessing function\n",
    "def preprocess_data(train_df, val_df, test_df, target_col, continuous_features, binary_features):\n",
    "    all_features = continuous_features + binary_features\n",
    "    \n",
    "    # Drop missing values\n",
    "    train_df = train_df.dropna(subset=all_features + [target_col])\n",
    "    val_df = val_df.dropna(subset=all_features + [target_col])\n",
    "    test_df = test_df.dropna(subset=all_features + [target_col])\n",
    "    \n",
    "    # Separate continuous and binary features\n",
    "    X_train_continuous = train_df[continuous_features]\n",
    "    X_val_continuous = val_df[continuous_features]\n",
    "    X_test_continuous = test_df[continuous_features]\n",
    "    \n",
    "    X_train_binary = train_df[binary_features]\n",
    "    X_val_binary = val_df[binary_features]\n",
    "    X_test_binary = test_df[binary_features]\n",
    "    \n",
    "    y_train = train_df[target_col]\n",
    "    y_val = val_df[target_col]\n",
    "    y_test = test_df[target_col]\n",
    "    \n",
    "    # Standardize only continuous features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_continuous_scaled = scaler.fit_transform(X_train_continuous)\n",
    "    X_val_continuous_scaled = scaler.transform(X_val_continuous)\n",
    "    X_test_continuous_scaled = scaler.transform(X_test_continuous)\n",
    "    \n",
    "    # Combine scaled continuous features with unscaled binary features\n",
    "    X_train_scaled = np.hstack([X_train_continuous_scaled, X_train_binary.values])\n",
    "    X_val_scaled = np.hstack([X_val_continuous_scaled, X_val_binary.values])\n",
    "    X_test_scaled = np.hstack([X_test_continuous_scaled, X_test_binary.values])\n",
    "    \n",
    "    return X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, scaler\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(y_true, y_pred, y_prob, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Overall metrics\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    # Class-specific metrics\n",
    "    precision_per_class = precision_score(y_true, y_pred, average=None)\n",
    "    recall_per_class = recall_score(y_true, y_pred, average=None)\n",
    "    f1_per_class = f1_score(y_true, y_pred, average=None)\n",
    "    \n",
    "    # Confusion matrix heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance metrics table\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.axis('tight')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    table_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Macro F1 Score', f'{f1_macro:.4f}'],\n",
    "        ['Overall Accuracy', f'{accuracy:.4f}'],\n",
    "        ['AUC', f'{auc:.4f}'],\n",
    "        ['', ''],  # Empty row for separation\n",
    "        ['Class 1 Precision', f'{precision_per_class[1]:.4f}'],\n",
    "        ['Class 1 Recall', f'{recall_per_class[1]:.4f}'],\n",
    "        ['Class 1 F1', f'{f1_per_class[1]:.4f}'],\n",
    "        ['', ''],  # Empty row for separation\n",
    "        ['Class 0 Precision', f'{precision_per_class[0]:.4f}'],\n",
    "        ['Class 0 Recall', f'{recall_per_class[0]:.4f}'],\n",
    "        ['Class 0 F1', f'{f1_per_class[0]:.4f}']\n",
    "    ]\n",
    "    \n",
    "    table = plt.table(cellText=table_data[1:], colLabels=table_data[0],\n",
    "                     cellLoc='center', loc='center',\n",
    "                     colWidths=[0.4, 0.3])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.5, 2)\n",
    "    \n",
    "    # Set table style\n",
    "    for i in range(len(table_data)):\n",
    "        for j in range(len(table_data[0])):\n",
    "            cell = table[(i, j)]\n",
    "            if i == 0:  # header\n",
    "                cell.set_facecolor('#4CAF50')\n",
    "                cell.set_text_props(weight='bold', color='white')\n",
    "            elif len(table_data[i]) > 0 and table_data[i][0] == '':  \n",
    "                cell.set_facecolor('#ffffff')\n",
    "                cell.set_text_props(color='white')\n",
    "            else:\n",
    "                cell.set_facecolor('#f0f0f0')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return {'confusion_matrix': cm, 'f1_macro': f1_macro, 'accuracy': accuracy, 'auc': auc,\n",
    "            'class_0_precision': precision_per_class[0], 'class_0_recall': recall_per_class[0], 'class_0_f1': f1_per_class[0],\n",
    "            'class_1_precision': precision_per_class[1], 'class_1_recall': recall_per_class[1], 'class_1_f1': f1_per_class[1]}\n",
    "\n",
    "# 1D_Up prediction\n",
    "print(\"=\" * 60)\n",
    "print(\"1D_Up Prediction Model - Random Forest Baseline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "X_train_1d, y_train_1d, X_val_1d, y_val_1d, X_test_1d, y_test_1d, scaler_1d = preprocess_data(\n",
    "    train_data, val_data, test_data, '1D_Up', continuous_features, binary_features)\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 400, 500], \n",
    "    'max_depth': [ 6, 8,10, None],    \n",
    "    'min_samples_split': [2, 5, 8], \n",
    "    'min_samples_leaf': [1, 2, 3],  \n",
    "    'max_features': ['sqrt', 'log2'] \n",
    "}\n",
    "\n",
    "print(\"Starting hyperparameter tuning for 1D model...\")\n",
    "grid_search_1d = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1,class_weight='balanced'),\n",
    "    param_grid, cv=tscv, scoring='f1', n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "grid_search_1d.fit(X_train_1d, y_train_1d)\n",
    "best_params_1d = grid_search_1d.best_params_\n",
    "print(f\"Best parameters for 1D model: {best_params_1d}\")\n",
    "print(f\"Best cross-validation F1 score: {grid_search_1d.best_score_:.4f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "final_model_1d = RandomForestClassifier(**best_params_1d, random_state=42, n_jobs=-1,class_weight='balanced')\n",
    "final_model_1d.fit(X_train_1d, y_train_1d)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_1d = final_model_1d.predict(X_test_1d)\n",
    "y_prob_1d = final_model_1d.predict_proba(X_test_1d)[:, 1]\n",
    "\n",
    "print(\"\\n1D Model Test Set Results:\")\n",
    "results_1d = evaluate_model(y_test_1d, y_pred_1d, y_prob_1d, \"1D_Up Prediction\")\n",
    "\n",
    "# 20D_Up prediction\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"20D_Up Prediction Model - Random Forest Baseline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "X_train_20d, y_train_20d, X_val_20d, y_val_20d, X_test_20d, y_test_20d, scaler_20d = preprocess_data(\n",
    "    train_data, val_data, test_data, '20D_Up', continuous_features, binary_features)\n",
    "\n",
    "print(\"Starting hyperparameter tuning for 20D model...\")\n",
    "grid_search_20d = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1,class_weight='balanced'),\n",
    "    param_grid, cv=tscv, scoring='f1', n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "grid_search_20d.fit(X_train_20d, y_train_20d)\n",
    "best_params_20d = grid_search_20d.best_params_\n",
    "print(f\"Best parameters for 20D model: {best_params_20d}\")\n",
    "print(f\"Best cross-validation F1 score: {grid_search_20d.best_score_:.4f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "final_model_20d = RandomForestClassifier(**best_params_20d, random_state=42, n_jobs=-1,class_weight='balanced')\n",
    "final_model_20d.fit(X_train_20d, y_train_20d)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_20d = final_model_20d.predict(X_test_20d)\n",
    "y_prob_20d = final_model_20d.predict_proba(X_test_20d)[:, 1]\n",
    "\n",
    "print(\"\\n20D Model Test Set Results:\")\n",
    "results_20d = evaluate_model(y_test_20d, y_pred_20d, y_prob_20d, \"20D_Up Prediction\")\n",
    "\n",
    "# SHAP Feature Importance Analysis\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SHAP Feature Importance Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = continuous_features + binary_features\n",
    "feature_names_array = np.array(feature_names)\n",
    "\n",
    "# Create SHAP explainers for both models\n",
    "print(\"Creating SHAP explainers...\")\n",
    "explainer_1d = shap.Explainer(final_model_1d, X_train_1d)\n",
    "explainer_20d = shap.Explainer(final_model_20d, X_train_20d)\n",
    "\n",
    "# Calculate SHAP values for test sets\n",
    "print(\"Calculating SHAP values for 1D model...\")\n",
    "shap_values_1d = explainer_1d(X_test_1d,check_additivity=False)\n",
    "\n",
    "print(\"Calculating SHAP values for 20D model...\")\n",
    "shap_values_20d = explainer_20d(X_test_20d,check_additivity=False)\n",
    "\n",
    "# 1D Model SHAP Analysis\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"1D_Up Model SHAP Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Summary plot for 1D model - use only positive class SHAP values\n",
    "if len(shap_values_1d.values.shape) == 3:\n",
    "    # Multi-class case - use positive class (class 1)\n",
    "    shap_vals_1d = shap_values_1d.values[:, :, 1]\n",
    "else:\n",
    "    # Binary case - use all values\n",
    "    shap_vals_1d = shap_values_1d.values\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_vals_1d, X_test_1d, feature_names=feature_names_array, show=False)\n",
    "plt.title('SHAP Summary Plot - 1D_Up Prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Waterfall plot for a single sample (1D model)\n",
    "plt.figure(figsize=(10, 6))\n",
    "if len(shap_values_1d.values.shape) == 3:\n",
    "    # For multi-class, create a new Explanation object for single class\n",
    "    sample_explanation = shap.Explanation(\n",
    "        values=shap_values_1d.values[0, :, 1],\n",
    "        base_values=shap_values_1d.base_values[0, 1] if hasattr(shap_values_1d.base_values, 'shape') and len(shap_values_1d.base_values.shape) > 1 else shap_values_1d.base_values[0],\n",
    "        data=shap_values_1d.data[0],\n",
    "        feature_names=feature_names_array\n",
    "    )\n",
    "else:\n",
    "    sample_explanation = shap_values_1d[0]\n",
    "\n",
    "shap.waterfall_plot(sample_explanation, show=False)\n",
    "plt.title('SHAP Waterfall Plot - Single Sample (1D_Up Prediction)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance ranking table for 1D model\n",
    "if len(shap_values_1d.values.shape) == 3:\n",
    "    mean_shap_1d = np.mean(shap_values_1d.values[:, :, 1], axis=0)\n",
    "    abs_mean_shap_1d = np.mean(np.abs(shap_values_1d.values[:, :, 1]), axis=0)\n",
    "else:\n",
    "    mean_shap_1d = np.mean(shap_values_1d.values, axis=0)\n",
    "    abs_mean_shap_1d = np.mean(np.abs(shap_values_1d.values), axis=0)\n",
    "\n",
    "importance_df_1d = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Mean_SHAP': mean_shap_1d,\n",
    "    'Abs_Mean_SHAP': abs_mean_shap_1d\n",
    "}).sort_values('Abs_Mean_SHAP', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance Ranking for 1D_Up Prediction (sorted by absolute value, preserving direction):\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"{'Rank':<4} {'Feature':<20} {'Mean SHAP':<12} {'|Mean SHAP|':<12} {'Direction':<12}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for i, (_, row) in enumerate(importance_df_1d.iterrows(), 1):\n",
    "    direction = \"↑ Positive\" if row['Mean_SHAP'] > 0 else \"↓ Negative\"\n",
    "    print(f\"{i:>2}. {row['Feature']:<20} {row['Mean_SHAP']:>+9.6f} {row['Abs_Mean_SHAP']:>11.6f} {direction}\")\n",
    "\n",
    "# 20D Model SHAP Analysis\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"20D_Up Model SHAP Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Summary plot for 20D model - use only positive class SHAP values\n",
    "if len(shap_values_20d.values.shape) == 3:\n",
    "    # Multi-class case - use positive class (class 1)\n",
    "    shap_vals_20d = shap_values_20d.values[:, :, 1]\n",
    "else:\n",
    "    # Binary case - use all values\n",
    "    shap_vals_20d = shap_values_20d.values\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_vals_20d, X_test_20d, feature_names=feature_names_array, show=False)\n",
    "plt.title('SHAP Summary Plot - 20D_Up Prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Waterfall plot for a single sample (20D model)\n",
    "plt.figure(figsize=(10, 6))\n",
    "if len(shap_values_20d.values.shape) == 3:\n",
    "    # For multi-class, create a new Explanation object for single class\n",
    "    sample_explanation = shap.Explanation(\n",
    "        values=shap_values_20d.values[0, :, 1],\n",
    "        base_values=shap_values_20d.base_values[0, 1] if hasattr(shap_values_20d.base_values, 'shape') and len(shap_values_20d.base_values.shape) > 1 else shap_values_20d.base_values[0],\n",
    "        data=shap_values_20d.data[0],\n",
    "        feature_names=feature_names_array\n",
    "    )\n",
    "else:\n",
    "    sample_explanation = shap_values_20d[0]\n",
    "\n",
    "shap.waterfall_plot(sample_explanation, show=False)\n",
    "plt.title('SHAP Waterfall Plot - Single Sample (20D_Up Prediction)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance ranking table for 20D model\n",
    "if len(shap_values_20d.values.shape) == 3:\n",
    "    mean_shap_20d = np.mean(shap_values_20d.values[:, :, 1], axis=0)\n",
    "    abs_mean_shap_20d = np.mean(np.abs(shap_values_20d.values[:, :, 1]), axis=0)\n",
    "else:\n",
    "    mean_shap_20d = np.mean(shap_values_20d.values, axis=0)\n",
    "    abs_mean_shap_20d = np.mean(np.abs(shap_values_20d.values), axis=0)\n",
    "\n",
    "importance_df_20d = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Mean_SHAP': mean_shap_20d,\n",
    "    'Abs_Mean_SHAP': abs_mean_shap_20d\n",
    "}).sort_values('Abs_Mean_SHAP', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance Ranking for 20D_Up Prediction (sorted by absolute value, preserving direction):\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"{'Rank':<4} {'Feature':<20} {'Mean SHAP':<12} {'|Mean SHAP|':<12} {'Direction':<12}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for i, (_, row) in enumerate(importance_df_20d.iterrows(), 1):\n",
    "    direction = \"↑ Positive\" if row['Mean_SHAP'] > 0 else \"↓ Negative\"\n",
    "    print(f\"{i:>2}. {row['Feature']:<20} {row['Mean_SHAP']:>+9.6f} {row['Abs_Mean_SHAP']:>11.6f} {direction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaf7b7d-fc65-4d76-8b7f-2afbbb70ad33",
   "metadata": {},
   "source": [
    "## Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742d41f5-efb6-42e0-91a7-93dfa23d9674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import shap\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('DATA.csv')\n",
    "\n",
    "# Define feature columns \n",
    "continuous_features = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct', 'J', \n",
    "                      'mfi', 'MACD', 'MACD_diff',  'BB_rel_pos', 'Vol_Change',\"Gold_Close\"]\n",
    "binary_features = ['MA5_GT_MA20']\n",
    "features = continuous_features + binary_features\n",
    "\n",
    "# Split data by company in chronological order\n",
    "train_data_list = []\n",
    "val_data_list = []\n",
    "test_data_list = []\n",
    "\n",
    "for company in df['Company'].unique():\n",
    "    company_data = df[df['Company'] == company].copy()\n",
    "    company_data = company_data.sort_values('Date')  # Ensure chronological order\n",
    "    \n",
    "    n_company = len(company_data)\n",
    "    train_size = int(0.7 * n_company)\n",
    "    val_size = int(0.15 * n_company)\n",
    "    \n",
    "    train_data_list.append(company_data.iloc[:train_size])\n",
    "    val_data_list.append(company_data.iloc[train_size:train_size+val_size])\n",
    "    test_data_list.append(company_data.iloc[train_size+val_size:])\n",
    "\n",
    "# Concatenate all companies' data\n",
    "train_data = pd.concat(train_data_list, ignore_index=True)\n",
    "val_data = pd.concat(val_data_list, ignore_index=True)\n",
    "test_data = pd.concat(test_data_list, ignore_index=True)\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")\n",
    "print(f\"Training set company distribution:\\n{train_data['Company'].value_counts().sort_index()}\")\n",
    "print(f\"Test set company distribution:\\n{test_data['Company'].value_counts().sort_index()}\")\n",
    "\n",
    "# Modified preprocessing function\n",
    "def preprocess_data(train_df, val_df, test_df, target_col, continuous_features, binary_features):\n",
    "    all_features = continuous_features + binary_features\n",
    "    \n",
    "    # Drop missing values\n",
    "    train_df = train_df.dropna(subset=all_features + [target_col])\n",
    "    val_df = val_df.dropna(subset=all_features + [target_col])\n",
    "    test_df = test_df.dropna(subset=all_features + [target_col])\n",
    "    \n",
    "    # Separate continuous and binary features\n",
    "    X_train_continuous = train_df[continuous_features]\n",
    "    X_val_continuous = val_df[continuous_features]\n",
    "    X_test_continuous = test_df[continuous_features]\n",
    "    \n",
    "    X_train_binary = train_df[binary_features]\n",
    "    X_val_binary = val_df[binary_features]\n",
    "    X_test_binary = test_df[binary_features]\n",
    "    \n",
    "    y_train = train_df[target_col]\n",
    "    y_val = val_df[target_col]\n",
    "    y_test = test_df[target_col]\n",
    "    \n",
    "    # Standardize only continuous features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_continuous_scaled = scaler.fit_transform(X_train_continuous)\n",
    "    X_val_continuous_scaled = scaler.transform(X_val_continuous)\n",
    "    X_test_continuous_scaled = scaler.transform(X_test_continuous)\n",
    "    \n",
    "    # Combine scaled continuous features with unscaled binary features\n",
    "    X_train_scaled = np.hstack([X_train_continuous_scaled, X_train_binary.values])\n",
    "    X_val_scaled = np.hstack([X_val_continuous_scaled, X_val_binary.values])\n",
    "    X_test_scaled = np.hstack([X_test_continuous_scaled, X_test_binary.values])\n",
    "    \n",
    "    return X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, scaler\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(y_true, y_pred, y_prob, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Overall metrics\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    # Class-specific metrics\n",
    "    precision_per_class = precision_score(y_true, y_pred, average=None)\n",
    "    recall_per_class = recall_score(y_true, y_pred, average=None)\n",
    "    f1_per_class = f1_score(y_true, y_pred, average=None)\n",
    "    \n",
    "    # Confusion matrix heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance metrics table\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.axis('tight')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    table_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Macro F1 Score', f'{f1_macro:.4f}'],\n",
    "        ['Overall Accuracy', f'{accuracy:.4f}'],\n",
    "        ['AUC', f'{auc:.4f}'],\n",
    "        ['', ''],  # Empty row for separation\n",
    "        ['Class 1 Precision', f'{precision_per_class[1]:.4f}'],\n",
    "        ['Class 1 Recall', f'{recall_per_class[1]:.4f}'],\n",
    "        ['Class 1 F1', f'{f1_per_class[1]:.4f}'],\n",
    "        ['', ''],  # Empty row for separation\n",
    "        ['Class 0 Precision', f'{precision_per_class[0]:.4f}'],\n",
    "        ['Class 0 Recall', f'{recall_per_class[0]:.4f}'],\n",
    "        ['Class 0 F1', f'{f1_per_class[0]:.4f}']\n",
    "    ]\n",
    "    \n",
    "    table = plt.table(cellText=table_data[1:], colLabels=table_data[0],\n",
    "                     cellLoc='center', loc='center',\n",
    "                     colWidths=[0.4, 0.3])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.5, 2)\n",
    "    \n",
    "    # Set table style\n",
    "    for i in range(len(table_data)):\n",
    "        for j in range(len(table_data[0])):\n",
    "            cell = table[(i, j)]\n",
    "            if i == 0:  # header\n",
    "                cell.set_facecolor('#4CAF50')\n",
    "                cell.set_text_props(weight='bold', color='white')\n",
    "            elif len(table_data[i]) > 0 and table_data[i][0] == '':  # empty rows\n",
    "                cell.set_facecolor('#ffffff')\n",
    "                cell.set_text_props(color='white')\n",
    "            else:\n",
    "                cell.set_facecolor('#f0f0f0')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return {'confusion_matrix': cm, 'f1_macro': f1_macro, 'accuracy': accuracy, 'auc': auc,\n",
    "            'class_0_precision': precision_per_class[0], 'class_0_recall': recall_per_class[0], 'class_0_f1': f1_per_class[0],\n",
    "            'class_1_precision': precision_per_class[1], 'class_1_recall': recall_per_class[1], 'class_1_f1': f1_per_class[1]}\n",
    "\n",
    "# 1D_Up prediction\n",
    "print(\"=\" * 60)\n",
    "print(\"1D_Up Prediction Model - Random Forest Baseline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "X_train_1d, y_train_1d, X_val_1d, y_val_1d, X_test_1d, y_test_1d, scaler_1d = preprocess_data(\n",
    "    train_data, val_data, test_data, '1D_Up', continuous_features, binary_features)\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 400, 500], \n",
    "    'max_depth': [ 6, 8,10, None],    \n",
    "    'min_samples_split': [2, 5, 8], \n",
    "    'min_samples_leaf': [1, 2, 3],  \n",
    "    'max_features': ['sqrt', 'log2'] \n",
    "}\n",
    "\n",
    "print(\"Starting hyperparameter tuning for 1D model...\")\n",
    "grid_search_1d = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1,class_weight='balanced'),\n",
    "    param_grid, cv=tscv, scoring='f1', n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "grid_search_1d.fit(X_train_1d, y_train_1d)\n",
    "best_params_1d = grid_search_1d.best_params_\n",
    "print(f\"Best parameters for 1D model: {best_params_1d}\")\n",
    "print(f\"Best cross-validation F1 score: {grid_search_1d.best_score_:.4f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "final_model_1d = RandomForestClassifier(**best_params_1d, random_state=42, n_jobs=-1,class_weight='balanced')\n",
    "final_model_1d.fit(X_train_1d, y_train_1d)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_1d = final_model_1d.predict(X_test_1d)\n",
    "y_prob_1d = final_model_1d.predict_proba(X_test_1d)[:, 1]\n",
    "\n",
    "print(\"\\n1D Model Test Set Results:\")\n",
    "results_1d = evaluate_model(y_test_1d, y_pred_1d, y_prob_1d, \"1D_Up Prediction\")\n",
    "\n",
    "# 20D_Up prediction\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"20D_Up Prediction Model - Random Forest Baseline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "X_train_20d, y_train_20d, X_val_20d, y_val_20d, X_test_20d, y_test_20d, scaler_20d = preprocess_data(\n",
    "    train_data, val_data, test_data, '20D_Up', continuous_features, binary_features)\n",
    "\n",
    "print(\"Starting hyperparameter tuning for 20D model...\")\n",
    "grid_search_20d = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1,class_weight='balanced'),\n",
    "    param_grid, cv=tscv, scoring='f1', n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "grid_search_20d.fit(X_train_20d, y_train_20d)\n",
    "best_params_20d = grid_search_20d.best_params_\n",
    "print(f\"Best parameters for 20D model: {best_params_20d}\")\n",
    "print(f\"Best cross-validation F1 score: {grid_search_20d.best_score_:.4f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "final_model_20d = RandomForestClassifier(**best_params_20d, random_state=42, n_jobs=-1,class_weight='balanced')\n",
    "final_model_20d.fit(X_train_20d, y_train_20d)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_20d = final_model_20d.predict(X_test_20d)\n",
    "y_prob_20d = final_model_20d.predict_proba(X_test_20d)[:, 1]\n",
    "\n",
    "print(\"\\n20D Model Test Set Results:\")\n",
    "results_20d = evaluate_model(y_test_20d, y_pred_20d, y_prob_20d, \"20D_Up Prediction\")\n",
    "\n",
    "# SHAP Feature Importance Analysis\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SHAP Feature Importance Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = continuous_features + binary_features\n",
    "feature_names_array = np.array(feature_names)\n",
    "\n",
    "# Create SHAP explainers for both models\n",
    "print(\"Creating SHAP explainers...\")\n",
    "explainer_1d = shap.Explainer(final_model_1d, X_train_1d)\n",
    "explainer_20d = shap.Explainer(final_model_20d, X_train_20d)\n",
    "\n",
    "# Calculate SHAP values for test sets\n",
    "print(\"Calculating SHAP values for 1D model...\")\n",
    "shap_values_1d = explainer_1d(X_test_1d,check_additivity=False)\n",
    "\n",
    "print(\"Calculating SHAP values for 20D model...\")\n",
    "shap_values_20d = explainer_20d(X_test_20d,check_additivity=False)\n",
    "\n",
    "# 1D Model SHAP Analysis\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"1D_Up Model SHAP Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Summary plot for 1D model - use only positive class SHAP values\n",
    "if len(shap_values_1d.values.shape) == 3:\n",
    "    # Multi-class case - use positive class (class 1)\n",
    "    shap_vals_1d = shap_values_1d.values[:, :, 1]\n",
    "else:\n",
    "    # Binary case - use all values\n",
    "    shap_vals_1d = shap_values_1d.values\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_vals_1d, X_test_1d, feature_names=feature_names_array, show=False)\n",
    "plt.title('SHAP Summary Plot - 1D_Up Prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Waterfall plot for a single sample (1D model)\n",
    "plt.figure(figsize=(10, 6))\n",
    "if len(shap_values_1d.values.shape) == 3:\n",
    "    # For multi-class, create a new Explanation object for single class\n",
    "    sample_explanation = shap.Explanation(\n",
    "        values=shap_values_1d.values[0, :, 1],\n",
    "        base_values=shap_values_1d.base_values[0, 1] if hasattr(shap_values_1d.base_values, 'shape') and len(shap_values_1d.base_values.shape) > 1 else shap_values_1d.base_values[0],\n",
    "        data=shap_values_1d.data[0],\n",
    "        feature_names=feature_names_array\n",
    "    )\n",
    "else:\n",
    "    sample_explanation = shap_values_1d[0]\n",
    "\n",
    "shap.waterfall_plot(sample_explanation, show=False)\n",
    "plt.title('SHAP Waterfall Plot - Single Sample (1D_Up Prediction)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance ranking table for 1D model\n",
    "if len(shap_values_1d.values.shape) == 3:\n",
    "    mean_shap_1d = np.mean(shap_values_1d.values[:, :, 1], axis=0)\n",
    "    abs_mean_shap_1d = np.mean(np.abs(shap_values_1d.values[:, :, 1]), axis=0)\n",
    "else:\n",
    "    mean_shap_1d = np.mean(shap_values_1d.values, axis=0)\n",
    "    abs_mean_shap_1d = np.mean(np.abs(shap_values_1d.values), axis=0)\n",
    "\n",
    "importance_df_1d = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Mean_SHAP': mean_shap_1d,\n",
    "    'Abs_Mean_SHAP': abs_mean_shap_1d\n",
    "}).sort_values('Abs_Mean_SHAP', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance Ranking for 1D_Up Prediction (sorted by absolute value, preserving direction):\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"{'Rank':<4} {'Feature':<20} {'Mean SHAP':<12} {'|Mean SHAP|':<12} {'Direction':<12}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for i, (_, row) in enumerate(importance_df_1d.iterrows(), 1):\n",
    "    direction = \"↑ Positive\" if row['Mean_SHAP'] > 0 else \"↓ Negative\"\n",
    "    print(f\"{i:>2}. {row['Feature']:<20} {row['Mean_SHAP']:>+9.6f} {row['Abs_Mean_SHAP']:>11.6f} {direction}\")\n",
    "\n",
    "# 20D Model SHAP Analysis\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"20D_Up Model SHAP Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Summary plot for 20D model - use only positive class SHAP values\n",
    "if len(shap_values_20d.values.shape) == 3:\n",
    "    # Multi-class case - use positive class (class 1)\n",
    "    shap_vals_20d = shap_values_20d.values[:, :, 1]\n",
    "else:\n",
    "    # Binary case - use all values\n",
    "    shap_vals_20d = shap_values_20d.values\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_vals_20d, X_test_20d, feature_names=feature_names_array, show=False)\n",
    "plt.title('SHAP Summary Plot - 20D_Up Prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Waterfall plot for a single sample (20D model)\n",
    "plt.figure(figsize=(10, 6))\n",
    "if len(shap_values_20d.values.shape) == 3:\n",
    "    # For multi-class, create a new Explanation object for single class\n",
    "    sample_explanation = shap.Explanation(\n",
    "        values=shap_values_20d.values[0, :, 1],\n",
    "        base_values=shap_values_20d.base_values[0, 1] if hasattr(shap_values_20d.base_values, 'shape') and len(shap_values_20d.base_values.shape) > 1 else shap_values_20d.base_values[0],\n",
    "        data=shap_values_20d.data[0],\n",
    "        feature_names=feature_names_array\n",
    "    )\n",
    "else:\n",
    "    sample_explanation = shap_values_20d[0]\n",
    "\n",
    "shap.waterfall_plot(sample_explanation, show=False)\n",
    "plt.title('SHAP Waterfall Plot - Single Sample (20D_Up Prediction)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance ranking table for 20D model\n",
    "if len(shap_values_20d.values.shape) == 3:\n",
    "    mean_shap_20d = np.mean(shap_values_20d.values[:, :, 1], axis=0)\n",
    "    abs_mean_shap_20d = np.mean(np.abs(shap_values_20d.values[:, :, 1]), axis=0)\n",
    "else:\n",
    "    mean_shap_20d = np.mean(shap_values_20d.values, axis=0)\n",
    "    abs_mean_shap_20d = np.mean(np.abs(shap_values_20d.values), axis=0)\n",
    "\n",
    "importance_df_20d = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Mean_SHAP': mean_shap_20d,\n",
    "    'Abs_Mean_SHAP': abs_mean_shap_20d\n",
    "}).sort_values('Abs_Mean_SHAP', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance Ranking for 20D_Up Prediction (sorted by absolute value, preserving direction):\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"{'Rank':<4} {'Feature':<20} {'Mean SHAP':<12} {'|Mean SHAP|':<12} {'Direction':<12}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for i, (_, row) in enumerate(importance_df_20d.iterrows(), 1):\n",
    "    direction = \"↑ Positive\" if row['Mean_SHAP'] > 0 else \"↓ Negative\"\n",
    "    print(f\"{i:>2}. {row['Feature']:<20} {row['Mean_SHAP']:>+9.6f} {row['Abs_Mean_SHAP']:>11.6f} {direction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c5d8dd-eff8-46d1-be4d-408ea323ff75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a961912-0ca2-4020-b390-44e756483b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
