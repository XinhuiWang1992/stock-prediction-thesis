{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890e18f6-c031-4eed-ab86-9d148b890524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualization\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('DATA.csv')\n",
    "\n",
    "# Print basic information\n",
    "print(\"=== Dataset Overview ===\")\n",
    "print(f\"Total Records: {len(df):,}\")\n",
    "print(f\"Number of Features: {df.shape[1]}\")\n",
    "print(f\"Time Range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "print(f\"Number of Companies: {df['Company'].nunique()}\")\n",
    "print(f\"Companies: {', '.join(df['Company'].unique())}\")\n",
    "\n",
    "# 1. Target Variable Distribution - 1D_Up (Pie Chart)\n",
    "plt.figure(figsize=(8, 6))\n",
    "counts_1d = df['1D_Up'].value_counts().sort_index()\n",
    "colors_1d = ['#FF6B6B', '#4ECDC4']\n",
    "\n",
    "wedges, texts, autotexts = plt.pie(counts_1d.values, \n",
    "                                   labels=['Down (0)', 'Up (1)'], \n",
    "                                   autopct='%1.1f%%',\n",
    "                                   colors=colors_1d,\n",
    "                                   startangle=90,\n",
    "                                   explode=(0.05, 0.05))\n",
    "\n",
    "plt.title('1D_Up Target Variable Distribution', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Target Variable Distribution - 20D_Up (Pie Chart)\n",
    "plt.figure(figsize=(8, 6))\n",
    "counts_20d = df['20D_Up'].value_counts().sort_index()\n",
    "colors_20d = ['#45B7D1', '#96CEB4']\n",
    "\n",
    "wedges, texts, autotexts = plt.pie(counts_20d.values, \n",
    "                                   labels=['Down (0)', 'Up (1)'], \n",
    "                                   autopct='%1.1f%%',\n",
    "                                   colors=colors_20d,\n",
    "                                   startangle=90,\n",
    "                                   explode=(0.05, 0.05))\n",
    "\n",
    "plt.title('20D_Up Target Variable Distribution', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Company Data Distribution (Bar Chart)\n",
    "plt.figure(figsize=(10, 6))\n",
    "company_counts = df['Company'].value_counts()\n",
    "company_colors = ['#667eea', '#f093fb', '#ff6b6b', '#feca57']\n",
    "\n",
    "bars = plt.bar(company_counts.index, company_counts.values, \n",
    "               color=company_colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "plt.title('Data Distribution by Company', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('Number of Records', fontsize=12)\n",
    "plt.xlabel('Company', fontsize=12)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 10,\n",
    "             f'{int(height):,}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Apple Target Variables Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "apple_data = df[df['Company'] == 'Apple']\n",
    "\n",
    "counts_1d_0 = len(apple_data[apple_data['1D_Up'] == 0])\n",
    "counts_1d_1 = len(apple_data[apple_data['1D_Up'] == 1])\n",
    "counts_20d_0 = len(apple_data[apple_data['20D_Up'] == 0])\n",
    "counts_20d_1 = len(apple_data[apple_data['20D_Up'] == 1])\n",
    "\n",
    "categories = ['1D_Up (0)', '1D_Up (1)', '20D_Up (0)', '20D_Up (1)']\n",
    "values = [counts_1d_0, counts_1d_1, counts_20d_0, counts_20d_1]\n",
    "bar_colors = [colors_1d[0], colors_1d[1], colors_20d[0], colors_20d[1]]\n",
    "\n",
    "bars = plt.bar(categories, values, color=bar_colors, alpha=0.8, \n",
    "               edgecolor='black', linewidth=1.5)\n",
    "\n",
    "plt.title('Apple - Target Variables Distribution', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xlabel('Target Variables', fontsize=12)\n",
    "\n",
    "# Add percentage labels on bars\n",
    "total = len(apple_data)\n",
    "for bar, value in zip(bars, values):\n",
    "    percentage = (value / total) * 100\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 5,\n",
    "             f'{value}\\n({percentage:.1f}%)', ha='center', va='bottom', \n",
    "             fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Tesla Target Variables Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "tesla_data = df[df['Company'] == 'Tesla']\n",
    "\n",
    "counts_1d_0 = len(tesla_data[tesla_data['1D_Up'] == 0])\n",
    "counts_1d_1 = len(tesla_data[tesla_data['1D_Up'] == 1])\n",
    "counts_20d_0 = len(tesla_data[tesla_data['20D_Up'] == 0])\n",
    "counts_20d_1 = len(tesla_data[tesla_data['20D_Up'] == 1])\n",
    "\n",
    "values = [counts_1d_0, counts_1d_1, counts_20d_0, counts_20d_1]\n",
    "\n",
    "bars = plt.bar(categories, values, color=bar_colors, alpha=0.8, \n",
    "               edgecolor='black', linewidth=1.5)\n",
    "\n",
    "plt.title('Tesla - Target Variables Distribution', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xlabel('Target Variables', fontsize=12)\n",
    "\n",
    "total = len(tesla_data)\n",
    "for bar, value in zip(bars, values):\n",
    "    percentage = (value / total) * 100\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 5,\n",
    "             f'{value}\\n({percentage:.1f}%)', ha='center', va='bottom', \n",
    "             fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Philips Target Variables Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "philips_data = df[df['Company'] == 'Philips']\n",
    "\n",
    "counts_1d_0 = len(philips_data[philips_data['1D_Up'] == 0])\n",
    "counts_1d_1 = len(philips_data[philips_data['1D_Up'] == 1])\n",
    "counts_20d_0 = len(philips_data[philips_data['20D_Up'] == 0])\n",
    "counts_20d_1 = len(philips_data[philips_data['20D_Up'] == 1])\n",
    "\n",
    "values = [counts_1d_0, counts_1d_1, counts_20d_0, counts_20d_1]\n",
    "\n",
    "bars = plt.bar(categories, values, color=bar_colors, alpha=0.8, \n",
    "               edgecolor='black', linewidth=1.5)\n",
    "\n",
    "plt.title('Philips - Target Variables Distribution', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xlabel('Target Variables', fontsize=12)\n",
    "\n",
    "total = len(philips_data)\n",
    "for bar, value in zip(bars, values):\n",
    "    percentage = (value / total) * 100\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 5,\n",
    "             f'{value}\\n({percentage:.1f}%)', ha='center', va='bottom', \n",
    "             fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7. Alibaba Target Variables Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "alibaba_data = df[df['Company'] == 'Alibaba']\n",
    "\n",
    "counts_1d_0 = len(alibaba_data[alibaba_data['1D_Up'] == 0])\n",
    "counts_1d_1 = len(alibaba_data[alibaba_data['1D_Up'] == 1])\n",
    "counts_20d_0 = len(alibaba_data[alibaba_data['20D_Up'] == 0])\n",
    "counts_20d_1 = len(alibaba_data[alibaba_data['20D_Up'] == 1])\n",
    "\n",
    "values = [counts_1d_0, counts_1d_1, counts_20d_0, counts_20d_1]\n",
    "\n",
    "bars = plt.bar(categories, values, color=bar_colors, alpha=0.8, \n",
    "               edgecolor='black', linewidth=1.5)\n",
    "\n",
    "plt.title('Alibaba - Target Variables Distribution', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xlabel('Target Variables', fontsize=12)\n",
    "\n",
    "total = len(alibaba_data)\n",
    "for bar, value in zip(bars, values):\n",
    "    percentage = (value / total) * 100\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 5,\n",
    "             f'{value}\\n({percentage:.1f}%)', ha='center', va='bottom', \n",
    "             fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 8. Company Performance Comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "companies = ['Apple', 'Tesla', 'Philips', 'Alibaba']\n",
    "companies_performance = []\n",
    "\n",
    "for company in companies:\n",
    "    company_data = df[df['Company'] == company]\n",
    "    total = len(company_data)\n",
    "    \n",
    "    success_1d = (company_data['1D_Up'] == 1).sum() / total * 100\n",
    "    success_20d = (company_data['20D_Up'] == 1).sum() / total * 100\n",
    "    \n",
    "    companies_performance.append([company, success_1d, success_20d])\n",
    "\n",
    "companies_perf_df = pd.DataFrame(companies_performance, \n",
    "                                columns=['Company', '1D_Up Success %', '20D_Up Success %'])\n",
    "\n",
    "x = np.arange(len(companies))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = plt.bar(x - width/2, companies_perf_df['1D_Up Success %'], width, \n",
    "                label='1D_Up Success %', color=colors_1d[1], alpha=0.8)\n",
    "bars2 = plt.bar(x + width/2, companies_perf_df['20D_Up Success %'], width,\n",
    "                label='20D_Up Success %', color=colors_20d[1], alpha=0.8)\n",
    "\n",
    "plt.ylabel('Success Rate (%)', fontsize=12)\n",
    "plt.xlabel('Company', fontsize=12)\n",
    "plt.title('Company Performance Comparison', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xticks(x, companies)\n",
    "plt.legend()\n",
    "plt.ylim(0, 70)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{height:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print Detailed Statistics\n",
    "print(\"\\n=== Detailed Target Variable Analysis ===\")\n",
    "for target in ['1D_Up', '20D_Up']:\n",
    "    print(f\"\\n{target} Distribution:\")\n",
    "    counts = df[target].value_counts().sort_index()\n",
    "    for value, count in counts.items():\n",
    "        percentage = (count / len(df)) * 100\n",
    "        print(f\"  {value}: {count:,} ({percentage:.2f}%)\")\n",
    "\n",
    "print(\"\\n=== Company-wise Target Variable Analysis ===\")\n",
    "for company in companies:\n",
    "    company_data = df[df['Company'] == company]\n",
    "    total = len(company_data)\n",
    "    print(f\"\\n{company} (Total: {total:,}):\")\n",
    "    \n",
    "    for target in ['1D_Up', '20D_Up']:\n",
    "        counts = company_data[target].value_counts().sort_index()\n",
    "        print(f\"  {target}:\")\n",
    "        for value, count in counts.items():\n",
    "            percentage = (count / total) * 100\n",
    "            print(f\"    {value}: {count:,} ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c199370-ff4c-43ff-8c0c-9ac5153fe75f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db951e05-fada-4034-a897-398363d78ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9. Company Stock Price Trends (2x2 Subplots)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Stock Price Trends by Company', fontsize=18, fontweight='bold', y=0.98)\n",
    "\n",
    "companies = ['Apple', 'Tesla', 'Philips', 'Alibaba']\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "\n",
    "for i, company in enumerate(companies):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    \n",
    "    company_data = df[df['Company'] == company].copy()\n",
    "    company_data['Date'] = pd.to_datetime(company_data['Date'])\n",
    "    company_data = company_data.sort_values('Date')\n",
    "    \n",
    "    axes[row, col].plot(company_data['Date'], company_data['Close'], \n",
    "                       color=colors[i], linewidth=2, alpha=0.8)\n",
    "    axes[row, col].set_title(f'{company} Stock Price', fontsize=14, fontweight='bold', pad=15)\n",
    "    axes[row, col].set_xlabel('Date', fontsize=12)\n",
    "    axes[row, col].set_ylabel('Close Price ($)', fontsize=12)\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Format x-axis to show dates nicely\n",
    "    axes[row, col].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add some statistics as text\n",
    "    min_price = company_data['Close'].min()\n",
    "    max_price = company_data['Close'].max()\n",
    "    avg_price = company_data['Close'].mean()\n",
    "    \n",
    "    stats_text = f'Min: ${min_price:.2f}\\nMax: ${max_price:.2f}\\nAvg: ${avg_price:.2f}'\n",
    "    axes[row, col].text(0.02, 0.98, stats_text, transform=axes[row, col].transAxes,\n",
    "                       verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                       fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.93)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76875bee-cee7-4229-8949-a1e6a527758f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f49b7-ae0f-48ad-9fd1-fb2c0c6cc559",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inter-Feature Correlation Analysis (Excluding Target Variables 1D_Up and 20D_Up)\n",
    "\n",
    "# Define feature categories\n",
    "stock_features = ['1D_PastChangePct', '5D_PastChangePct','20D_PastChangePct', 'J', \n",
    "                  'mfi', 'MACD', 'MACD_diff',  'BB_rel_pos', 'Vol_Change','MA5_GT_MA20']\n",
    "\n",
    "other_assets_features = ['Bitcoin_Close', 'Gold_Close']\n",
    "\n",
    "interest_rate_feature = ['Interest_Rate']\n",
    "\n",
    "# Combine all features (excluding target variables)\n",
    "all_features = stock_features + other_assets_features + interest_rate_feature\n",
    "\n",
    "# Filter features that exist in the dataset\n",
    "available_features = [f for f in all_features if f in df.columns]\n",
    "print(f\"Available features: {len(available_features)} / {len(all_features)}\")\n",
    "print(f\"Available features: {available_features}\")\n",
    "\n",
    "# 1. Complete Feature Correlation Matrix\n",
    "\n",
    "if len(available_features) > 1:\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = df[available_features].corr()\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(correlation_matrix, \n",
    "                annot=True, \n",
    "                cmap='RdBu_r', \n",
    "                center=0, \n",
    "                square=True, \n",
    "                fmt='.2f', \n",
    "                cbar_kws={'shrink': 0.8, 'label': 'Correlation Coefficient'},\n",
    "                linewidths=0.5)\n",
    "    \n",
    "    plt.title('Inter-Feature Correlation Matrix\\n(Stock Technical Indicators + Other Assets + Interest Rate)', \n",
    "              fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "    plt.yticks(rotation=0, fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 2. High Correlation Feature Pairs Identification\n",
    "\n",
    "def find_high_correlations(corr_matrix, threshold=0.7):\n",
    "    \"\"\"Find highly correlated feature pairs\"\"\"\n",
    "    high_corr_pairs = []\n",
    "    \n",
    "    # Get upper triangle matrix (avoid duplicates and self-correlation)\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            corr_value = corr_matrix.iloc[i, j]\n",
    "            if abs(corr_value) >= threshold:\n",
    "                high_corr_pairs.append({\n",
    "                    'Feature1': corr_matrix.columns[i],\n",
    "                    'Feature2': corr_matrix.columns[j],\n",
    "                    'Correlation': corr_value\n",
    "                })\n",
    "    \n",
    "    return sorted(high_corr_pairs, key=lambda x: abs(x['Correlation']), reverse=True)\n",
    "\n",
    "if len(available_features) > 1:\n",
    "    print(\"\\n=== High Correlation Feature Pairs Analysis ===\")\n",
    "    \n",
    "    # Find feature pairs with |correlation| > 0.7\n",
    "    high_corr_pairs = find_high_correlations(correlation_matrix, threshold=0.7)\n",
    "    \n",
    "    if high_corr_pairs:\n",
    "        print(f\"Found {len(high_corr_pairs)} highly correlated feature pairs (|correlation| >= 0.7):\")\n",
    "        for pair in high_corr_pairs:\n",
    "            print(f\"  {pair['Feature1']} ↔ {pair['Feature2']}: {pair['Correlation']:.3f}\")\n",
    "    else:\n",
    "        print(\"No highly correlated feature pairs found (|correlation| >= 0.7)\")\n",
    "    \n",
    "    # Also check medium correlation (0.5-0.7)\n",
    "    medium_corr_pairs = find_high_correlations(correlation_matrix, threshold=0.5)\n",
    "    medium_corr_pairs = [p for p in medium_corr_pairs if abs(p['Correlation']) < 0.7]\n",
    "    \n",
    "    if medium_corr_pairs:\n",
    "        print(f\"\\nMedium correlation feature pairs (0.5 <= |correlation| < 0.7):\")\n",
    "        for pair in medium_corr_pairs[:10]:  # Show only top 10\n",
    "            print(f\"  {pair['Feature1']} ↔ {pair['Feature2']}: {pair['Correlation']:.3f}\")\n",
    "\n",
    "# 3. Category-wise Correlation Analysis\n",
    "\n",
    "def analyze_category_correlations(df, category_features, category_name):\n",
    "    \"\"\"Analyze correlations within a specific category\"\"\"\n",
    "    available_in_category = [f for f in category_features if f in df.columns]\n",
    "    \n",
    "    if len(available_in_category) > 1:\n",
    "        print(f\"\\n=== {category_name} Internal Correlations ===\")\n",
    "        print(f\"Available features: {available_in_category}\")\n",
    "        \n",
    "        category_corr = df[available_in_category].corr()\n",
    "        \n",
    "        # Find high correlations within category\n",
    "        high_corr = find_high_correlations(category_corr, threshold=0.5)\n",
    "        if high_corr:\n",
    "            print(\"High correlations within category:\")\n",
    "            for pair in high_corr:\n",
    "                print(f\"  {pair['Feature1']} ↔ {pair['Feature2']}: {pair['Correlation']:.3f}\")\n",
    "        else:\n",
    "            print(\"No significant correlations within category\")\n",
    "        \n",
    "        return category_corr\n",
    "    else:\n",
    "        print(f\"\\n=== {category_name} ===\")\n",
    "        print(f\"Insufficient features (<2) for correlation analysis\")\n",
    "        return None\n",
    "\n",
    "# Analyze intra-category correlations\n",
    "stock_corr = analyze_category_correlations(df, stock_features, \"Stock Technical Indicators\")\n",
    "assets_corr = analyze_category_correlations(df, other_assets_features, \"Other Assets\")\n",
    "\n",
    "# 4. Cross-Category Correlation Analysis\n",
    "\n",
    "print(\"\\n=== Cross-Category Correlation Analysis ===\")\n",
    "\n",
    "# Stock features vs Other assets\n",
    "available_stock = [f for f in stock_features if f in df.columns]\n",
    "available_assets = [f for f in other_assets_features if f in df.columns]\n",
    "available_interest = [f for f in interest_rate_feature if f in df.columns]\n",
    "\n",
    "if available_stock and available_assets:\n",
    "    print(\"\\nStock Technical Indicators vs Other Assets:\")\n",
    "    for stock_feat in available_stock:\n",
    "        for asset_feat in available_assets:\n",
    "            corr = df[stock_feat].corr(df[asset_feat])\n",
    "            if abs(corr) > 0.3:  # Only show stronger correlations\n",
    "                print(f\"  {stock_feat} ↔ {asset_feat}: {corr:.3f}\")\n",
    "\n",
    "if available_stock and available_interest:\n",
    "    print(\"\\nStock Technical Indicators vs Interest Rate:\")\n",
    "    for stock_feat in available_stock:\n",
    "        for int_feat in available_interest:\n",
    "            corr = df[stock_feat].corr(df[int_feat])\n",
    "            if abs(corr) > 0.3:\n",
    "                print(f\"  {stock_feat} ↔ {int_feat}: {corr:.3f}\")\n",
    "\n",
    "if available_assets and available_interest:\n",
    "    print(\"\\nOther Assets vs Interest Rate:\")\n",
    "    for asset_feat in available_assets:\n",
    "        for int_feat in available_interest:\n",
    "            corr = df[asset_feat].corr(df[int_feat])\n",
    "            if abs(corr) > 0.3:\n",
    "                print(f\"  {asset_feat} ↔ {int_feat}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1197b108-34ab-4728-a7e3-5a35304bec61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16b08163-150f-4cd1-821a-6b90d81659e6",
   "metadata": {},
   "source": [
    "## base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958c1e5b-16e7-4d5e-b4d3-d879dffbbf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('DATA.csv')\n",
    "\n",
    "# Define feature columns\n",
    "continuous_features = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct',  'J', \n",
    "                      'mfi', 'MACD', 'MACD_diff', 'BB_rel_pos', 'Vol_Change']\n",
    "binary_features = ['MA5_GT_MA20']\n",
    "features = continuous_features + binary_features\n",
    "\n",
    "# Split data by company in chronological order\n",
    "train_data_list = []\n",
    "val_data_list = []\n",
    "test_data_list = []\n",
    "\n",
    "for company in df['Company'].unique():\n",
    "    company_data = df[df['Company'] == company].copy()\n",
    "    company_data = company_data.sort_values('Date')  \n",
    "    \n",
    "    n_company = len(company_data)\n",
    "    train_size = int(0.7 * n_company)\n",
    "    val_size = int(0.15 * n_company)\n",
    "    \n",
    "    train_data_list.append(company_data.iloc[:train_size])\n",
    "    val_data_list.append(company_data.iloc[train_size:train_size+val_size])\n",
    "    test_data_list.append(company_data.iloc[train_size+val_size:])\n",
    "\n",
    "# Concatenate all companies' data\n",
    "train_data = pd.concat(train_data_list, ignore_index=True)\n",
    "val_data = pd.concat(val_data_list, ignore_index=True)\n",
    "test_data = pd.concat(test_data_list, ignore_index=True)\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")\n",
    "print(f\"Training set company distribution:\\n{train_data['Company'].value_counts().sort_index()}\")\n",
    "print(f\"Test set company distribution:\\n{test_data['Company'].value_counts().sort_index()}\")\n",
    "\n",
    "# Modified preprocessing function\n",
    "def preprocess_data(train_df, val_df, test_df, target_col, continuous_features, binary_features):\n",
    "    all_features = continuous_features + binary_features\n",
    "    \n",
    "    # Drop missing values\n",
    "    train_df = train_df.dropna(subset=all_features + [target_col])\n",
    "    val_df = val_df.dropna(subset=all_features + [target_col])\n",
    "    test_df = test_df.dropna(subset=all_features + [target_col])\n",
    "    \n",
    "    # Separate continuous and binary features\n",
    "    X_train_continuous = train_df[continuous_features]\n",
    "    X_val_continuous = val_df[continuous_features]\n",
    "    X_test_continuous = test_df[continuous_features]\n",
    "    \n",
    "    X_train_binary = train_df[binary_features]\n",
    "    X_val_binary = val_df[binary_features]\n",
    "    X_test_binary = test_df[binary_features]\n",
    "    \n",
    "    y_train = train_df[target_col]\n",
    "    y_val = val_df[target_col]\n",
    "    y_test = test_df[target_col]\n",
    "    \n",
    "    # Standardize only continuous features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_continuous_scaled = scaler.fit_transform(X_train_continuous)\n",
    "    X_val_continuous_scaled = scaler.transform(X_val_continuous)\n",
    "    X_test_continuous_scaled = scaler.transform(X_test_continuous)\n",
    "    \n",
    "    # Combine scaled continuous features with unscaled binary features\n",
    "    X_train_scaled = np.hstack([X_train_continuous_scaled, X_train_binary.values])\n",
    "    X_val_scaled = np.hstack([X_val_continuous_scaled, X_val_binary.values])\n",
    "    X_test_scaled = np.hstack([X_test_continuous_scaled, X_test_binary.values])\n",
    "    \n",
    "    return X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, scaler\n",
    "\n",
    "# NEW Evaluation function\n",
    "def evaluate_model(y_true, y_pred, y_prob, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Overall metrics\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    # Class-specific metrics\n",
    "    precision_per_class = precision_score(y_true, y_pred, average=None)\n",
    "    recall_per_class = recall_score(y_true, y_pred, average=None)\n",
    "    f1_per_class = f1_score(y_true, y_pred, average=None)\n",
    "    \n",
    "    # Confusion matrix heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance metrics table - NEW FORMAT\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.axis('tight')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    table_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Macro F1 Score', f'{f1_macro:.4f}'],\n",
    "        ['Overall Accuracy', f'{accuracy:.4f}'],\n",
    "        ['AUC', f'{auc:.4f}'],\n",
    "        ['', ''],  # Empty row for separation\n",
    "        ['Class 1 Precision', f'{precision_per_class[1]:.4f}'],\n",
    "        ['Class 1 Recall', f'{recall_per_class[1]:.4f}'],\n",
    "        ['Class 1 F1', f'{f1_per_class[1]:.4f}'],\n",
    "        ['', ''],  # Empty row for separation\n",
    "        ['Class 0 Precision', f'{precision_per_class[0]:.4f}'],\n",
    "        ['Class 0 Recall', f'{recall_per_class[0]:.4f}'],\n",
    "        ['Class 0 F1', f'{f1_per_class[0]:.4f}']\n",
    "    ]\n",
    "    \n",
    "    table = plt.table(cellText=table_data[1:], colLabels=table_data[0],\n",
    "                     cellLoc='center', loc='center',\n",
    "                     colWidths=[0.4, 0.3])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.5, 2)\n",
    "    \n",
    "    # Set table style\n",
    "    for i in range(len(table_data)):\n",
    "        for j in range(len(table_data[0])):\n",
    "            cell = table[(i, j)]\n",
    "            if i == 0:  # header\n",
    "                cell.set_facecolor('#4CAF50')\n",
    "                cell.set_text_props(weight='bold', color='white')\n",
    "            elif len(table_data[i]) > 0 and table_data[i][0] == '':  # empty rows\n",
    "                cell.set_facecolor('#ffffff')\n",
    "                cell.set_text_props(color='white')\n",
    "            else:\n",
    "                cell.set_facecolor('#f0f0f0')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return {'confusion_matrix': cm, 'f1_macro': f1_macro, 'accuracy': accuracy, 'auc': auc,\n",
    "            'class_0_precision': precision_per_class[0], 'class_0_recall': recall_per_class[0], 'class_0_f1': f1_per_class[0],\n",
    "            'class_1_precision': precision_per_class[1], 'class_1_recall': recall_per_class[1], 'class_1_f1': f1_per_class[1]}\n",
    "\n",
    "# 1D_Up prediction\n",
    "print(\"=\" * 50)\n",
    "print(\"1D_Up Prediction Model\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "X_train_1d, y_train_1d, X_val_1d, y_val_1d, X_test_1d, y_test_1d, scaler_1d = preprocess_data(\n",
    "    train_data, val_data, test_data, '1D_Up', continuous_features, binary_features)\n",
    "\n",
    "# TimeSeriesSplit cross-validation to select best regularization parameter\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid_search_1d = GridSearchCV(\n",
    "    LogisticRegression(penalty='l1', solver='liblinear', random_state=42),\n",
    "    param_grid, cv=tscv, scoring='f1', n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_1d.fit(X_train_1d, y_train_1d)\n",
    "best_C_1d = grid_search_1d.best_params_['C']\n",
    "print(f\"Best regularization parameter C: {best_C_1d}\")\n",
    "\n",
    "# Train final model with best parameter\n",
    "final_model_1d = LogisticRegression(penalty='l1', solver='liblinear', C=best_C_1d, random_state=42)\n",
    "final_model_1d.fit(X_train_1d, y_train_1d)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_1d = final_model_1d.predict(X_test_1d)\n",
    "y_prob_1d = final_model_1d.predict_proba(X_test_1d)[:, 1]\n",
    "\n",
    "print(\"\\nTest Set Results:\")\n",
    "results_1d = evaluate_model(y_test_1d, y_pred_1d, y_prob_1d, \"1D_Up Prediction\")\n",
    "\n",
    "# 20D_Up prediction\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"20D_Up Prediction Model\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "X_train_20d, y_train_20d, X_val_20d, y_val_20d, X_test_20d, y_test_20d, scaler_20d = preprocess_data(\n",
    "    train_data, val_data, test_data, '20D_Up', continuous_features, binary_features)\n",
    "\n",
    "# TimeSeriesSplit cross-validation to select best regularization parameter\n",
    "grid_search_20d = GridSearchCV(\n",
    "    LogisticRegression(penalty='l1', solver='liblinear', random_state=42),\n",
    "    param_grid, cv=tscv, scoring='f1', n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_20d.fit(X_train_20d, y_train_20d)\n",
    "best_C_20d = grid_search_20d.best_params_['C']\n",
    "print(f\"Best regularization parameter C: {best_C_20d}\")\n",
    "\n",
    "# Train final model with best parameter\n",
    "final_model_20d = LogisticRegression(penalty='l1', solver='liblinear', C=best_C_20d, random_state=42)\n",
    "final_model_20d.fit(X_train_20d, y_train_20d)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_20d = final_model_20d.predict(X_test_20d)\n",
    "y_prob_20d = final_model_20d.predict_proba(X_test_20d)[:, 1]\n",
    "\n",
    "print(\"\\nTest Set Results:\")\n",
    "results_20d = evaluate_model(y_test_20d, y_pred_20d, y_prob_20d, \"20D_Up Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba0459c-4b9f-4e80-9300-951a42683bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coefficients(model, feature_names, model_name):\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    coefs = model.coef_[0]\n",
    "    coef_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefs})\n",
    "    coef_df = coef_df.sort_values(by='Coefficient', key=abs, ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, max(6, 0.4*len(coef_df))))\n",
    "    sns.barplot(x='Coefficient', y='Feature', data=coef_df, palette='coolwarm')\n",
    "    plt.axvline(0, color='gray', linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Optionally print table too\n",
    "    print(coef_df.to_string(index=False))\n",
    "plot_coefficients(final_model_1d, features, \"1D_Up Prediction\")\n",
    "plot_coefficients(final_model_20d, features, \"20D_Up Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40764c85-90b2-4e11-b006-5d100c831571",
   "metadata": {},
   "source": [
    "## add BTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a99d127-6666-4718-a2ad-d86e95534983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('DATA.csv')\n",
    "\n",
    "# Define feature columns\n",
    "continuous_features = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct',  'J', \n",
    "                      'mfi', 'MACD', 'MACD_diff',  'BB_rel_pos', 'Vol_Change', 'Bitcoin_Close']\n",
    "binary_features = ['MA5_GT_MA20']\n",
    "features = continuous_features + binary_features\n",
    "\n",
    "# Split data by company in chronological order\n",
    "train_data_list = []\n",
    "val_data_list = []\n",
    "test_data_list = []\n",
    "\n",
    "for company in df['Company'].unique():\n",
    "    company_data = df[df['Company'] == company].copy()\n",
    "    company_data = company_data.sort_values('Date')  \n",
    "    \n",
    "    n_company = len(company_data)\n",
    "    train_size = int(0.7 * n_company)\n",
    "    val_size = int(0.15 * n_company)\n",
    "    \n",
    "    train_data_list.append(company_data.iloc[:train_size])\n",
    "    val_data_list.append(company_data.iloc[train_size:train_size+val_size])\n",
    "    test_data_list.append(company_data.iloc[train_size+val_size:])\n",
    "\n",
    "# Concatenate all companies' data\n",
    "train_data = pd.concat(train_data_list, ignore_index=True)\n",
    "val_data = pd.concat(val_data_list, ignore_index=True)\n",
    "test_data = pd.concat(test_data_list, ignore_index=True)\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")\n",
    "print(f\"Training set company distribution:\\n{train_data['Company'].value_counts().sort_index()}\")\n",
    "print(f\"Test set company distribution:\\n{test_data['Company'].value_counts().sort_index()}\")\n",
    "\n",
    "# Modified preprocessing function\n",
    "def preprocess_data(train_df, val_df, test_df, target_col, continuous_features, binary_features):\n",
    "    all_features = continuous_features + binary_features\n",
    "    \n",
    "    # Drop missing values\n",
    "    train_df = train_df.dropna(subset=all_features + [target_col])\n",
    "    val_df = val_df.dropna(subset=all_features + [target_col])\n",
    "    test_df = test_df.dropna(subset=all_features + [target_col])\n",
    "    \n",
    "    # Separate continuous and binary features\n",
    "    X_train_continuous = train_df[continuous_features]\n",
    "    X_val_continuous = val_df[continuous_features]\n",
    "    X_test_continuous = test_df[continuous_features]\n",
    "    \n",
    "    X_train_binary = train_df[binary_features]\n",
    "    X_val_binary = val_df[binary_features]\n",
    "    X_test_binary = test_df[binary_features]\n",
    "    \n",
    "    y_train = train_df[target_col]\n",
    "    y_val = val_df[target_col]\n",
    "    y_test = test_df[target_col]\n",
    "    \n",
    "    # Standardize only continuous features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_continuous_scaled = scaler.fit_transform(X_train_continuous)\n",
    "    X_val_continuous_scaled = scaler.transform(X_val_continuous)\n",
    "    X_test_continuous_scaled = scaler.transform(X_test_continuous)\n",
    "    \n",
    "    # Combine scaled continuous features with unscaled binary features\n",
    "    X_train_scaled = np.hstack([X_train_continuous_scaled, X_train_binary.values])\n",
    "    X_val_scaled = np.hstack([X_val_continuous_scaled, X_val_binary.values])\n",
    "    X_test_scaled = np.hstack([X_test_continuous_scaled, X_test_binary.values])\n",
    "    \n",
    "    return X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, scaler\n",
    "\n",
    "# NEW: Function to find optimal threshold based on validation set F1 score\n",
    "def find_optimal_threshold(y_val, y_prob_val):\n",
    "    \"\"\"\n",
    "    Find the threshold that maximizes F1 score on validation set\n",
    "    \"\"\"\n",
    "    thresholds = np.arange(0.1, 0.9, 0.01)  # Test thresholds from 0.1 to 0.9\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0.5\n",
    "    f1_scores = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred_val = (y_prob_val >= threshold).astype(int)\n",
    "        f1 = f1_score(y_val, y_pred_val)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    # Plot F1 scores vs thresholds\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(thresholds, f1_scores, 'b-', linewidth=2)\n",
    "    plt.axvline(x=best_threshold, color='r', linestyle='--', linewidth=2, \n",
    "                label=f'Best Threshold = {best_threshold:.3f}')\n",
    "    plt.axvline(x=0.5, color='g', linestyle='--', linewidth=2, \n",
    "                label=f'Default Threshold = 0.5')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('F1 Score vs Threshold on Validation Set')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    return best_threshold, best_f1\n",
    "\n",
    "# Modified evaluation function to compare different thresholds\n",
    "def evaluate_model_with_thresholds(y_true, y_prob, default_threshold=0.5, optimal_threshold=None, model_name=\"\"):\n",
    "    \"\"\"\n",
    "    Evaluate model with both default (0.5) and optimal thresholds\n",
    "    \"\"\"\n",
    "    # Predictions with default threshold\n",
    "    y_pred_default = (y_prob >= default_threshold).astype(int)\n",
    "    \n",
    "    # Predictions with optimal threshold\n",
    "    y_pred_optimal = (y_prob >= optimal_threshold).astype(int)\n",
    "    \n",
    "    # Calculate metrics for both thresholds\n",
    "    metrics_default = {\n",
    "        'threshold': default_threshold,\n",
    "        'f1_macro': f1_score(y_true, y_pred_default, average='macro'),\n",
    "        'f1_binary': f1_score(y_true, y_pred_default),\n",
    "        'accuracy': accuracy_score(y_true, y_pred_default),\n",
    "        'precision': precision_score(y_true, y_pred_default),\n",
    "        'recall': recall_score(y_true, y_pred_default),\n",
    "        'auc': roc_auc_score(y_true, y_prob)\n",
    "    }\n",
    "    \n",
    "    metrics_optimal = {\n",
    "        'threshold': optimal_threshold,\n",
    "        'f1_macro': f1_score(y_true, y_pred_optimal, average='macro'),\n",
    "        'f1_binary': f1_score(y_true, y_pred_optimal),\n",
    "        'accuracy': accuracy_score(y_true, y_pred_optimal),\n",
    "        'precision': precision_score(y_true, y_pred_optimal),\n",
    "        'recall': recall_score(y_true, y_pred_optimal),\n",
    "        'auc': roc_auc_score(y_true, y_prob)\n",
    "    }\n",
    "    \n",
    "    # Create comparison table\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.axis('tight')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    table_data = [\n",
    "        ['Metric', 'Default (0.5)', 'Optimized', 'Improvement'],\n",
    "        ['Threshold', f'{metrics_default[\"threshold\"]:.3f}', f'{metrics_optimal[\"threshold\"]:.3f}', '-'],\n",
    "        ['F1 Score (Binary)', f'{metrics_default[\"f1_binary\"]:.4f}', f'{metrics_optimal[\"f1_binary\"]:.4f}', \n",
    "         f'{metrics_optimal[\"f1_binary\"] - metrics_default[\"f1_binary\"]:+.4f}'],\n",
    "        ['F1 Score (Macro)', f'{metrics_default[\"f1_macro\"]:.4f}', f'{metrics_optimal[\"f1_macro\"]:.4f}', \n",
    "         f'{metrics_optimal[\"f1_macro\"] - metrics_default[\"f1_macro\"]:+.4f}'],\n",
    "        ['Accuracy', f'{metrics_default[\"accuracy\"]:.4f}', f'{metrics_optimal[\"accuracy\"]:.4f}', \n",
    "         f'{metrics_optimal[\"accuracy\"] - metrics_default[\"accuracy\"]:+.4f}'],\n",
    "        ['Precision', f'{metrics_default[\"precision\"]:.4f}', f'{metrics_optimal[\"precision\"]:.4f}', \n",
    "         f'{metrics_optimal[\"precision\"] - metrics_default[\"precision\"]:+.4f}'],\n",
    "        ['Recall', f'{metrics_default[\"recall\"]:.4f}', f'{metrics_optimal[\"recall\"]:.4f}', \n",
    "         f'{metrics_optimal[\"recall\"] - metrics_default[\"recall\"]:+.4f}'],\n",
    "        ['AUC', f'{metrics_default[\"auc\"]:.4f}', f'{metrics_optimal[\"auc\"]:.4f}', 'Same']\n",
    "    ]\n",
    "    \n",
    "    table = plt.table(cellText=table_data[1:], colLabels=table_data[0],\n",
    "                     cellLoc='center', loc='center',\n",
    "                     colWidths=[0.25, 0.2, 0.2, 0.2])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(11)\n",
    "    table.scale(1.2, 2)\n",
    "    \n",
    "    # Set table style\n",
    "    for i in range(len(table_data)):\n",
    "        for j in range(len(table_data[0])):\n",
    "            cell = table[(i, j)]\n",
    "            if i == 0:  # header\n",
    "                cell.set_facecolor('#4CAF50')\n",
    "                cell.set_text_props(weight='bold', color='white')\n",
    "            elif j == 3 and i > 1 and i < 7:  \n",
    "                improvement = float(table_data[i][j].replace('+', ''))\n",
    "                if improvement > 0:\n",
    "                    cell.set_facecolor('#e8f5e8') \n",
    "                elif improvement < 0:\n",
    "                    cell.set_facecolor('#ffe8e8') \n",
    "                else:\n",
    "                    cell.set_facecolor('#f0f0f0')\n",
    "            else:\n",
    "                cell.set_facecolor('#f0f0f0')\n",
    "    \n",
    "    plt.title(f'{model_name} - Threshold Comparison Results', fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.show()\n",
    "    \n",
    "    # Side-by-side confusion matrices\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Confusion matrix for default threshold\n",
    "    cm_default = confusion_matrix(y_true, y_pred_default)\n",
    "    sns.heatmap(cm_default, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
    "                xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                yticklabels=['Actual 0', 'Actual 1'])\n",
    "    ax1.set_title(f'Default Threshold (0.5)\\nF1 Score: {metrics_default[\"f1_binary\"]:.4f}')\n",
    "    ax1.set_ylabel('Actual')\n",
    "    ax1.set_xlabel('Predicted')\n",
    "    \n",
    "    # Confusion matrix for optimal threshold\n",
    "    cm_optimal = confusion_matrix(y_true, y_pred_optimal)\n",
    "    sns.heatmap(cm_optimal, annot=True, fmt='d', cmap='Greens', ax=ax2,\n",
    "                xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                yticklabels=['Actual 0', 'Actual 1'])\n",
    "    ax2.set_title(f'Optimal Threshold ({optimal_threshold:.3f})\\nF1 Score: {metrics_optimal[\"f1_binary\"]:.4f}')\n",
    "    ax2.set_ylabel('Actual')\n",
    "    ax2.set_xlabel('Predicted')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return metrics_default, metrics_optimal\n",
    "\n",
    "# 1D_Up prediction with threshold optimization\n",
    "print(\"=\" * 50)\n",
    "print(\"1D_Up Prediction Model with Threshold Optimization\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "X_train_1d, y_train_1d, X_val_1d, y_val_1d, X_test_1d, y_test_1d, scaler_1d = preprocess_data(\n",
    "    train_data, val_data, test_data, '1D_Up', continuous_features, binary_features)\n",
    "\n",
    "# TimeSeriesSplit cross-validation to select best regularization parameter\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid_search_1d = GridSearchCV(\n",
    "    LogisticRegression(penalty='l1', solver='liblinear', random_state=42),\n",
    "    param_grid, cv=tscv, scoring='f1', n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_1d.fit(X_train_1d, y_train_1d)\n",
    "best_C_1d = grid_search_1d.best_params_['C']\n",
    "print(f\"Best regularization parameter C: {best_C_1d}\")\n",
    "\n",
    "# Train final model with best parameter\n",
    "final_model_1d = LogisticRegression(penalty='l1', solver='liblinear', C=best_C_1d, random_state=42)\n",
    "final_model_1d.fit(X_train_1d, y_train_1d)\n",
    "\n",
    "# Get validation set predictions for threshold optimization\n",
    "y_prob_val_1d = final_model_1d.predict_proba(X_val_1d)[:, 1]\n",
    "\n",
    "# Find optimal threshold on validation set\n",
    "print(\"\\nFinding optimal threshold on validation set...\")\n",
    "optimal_threshold_1d, best_val_f1_1d = find_optimal_threshold(y_val_1d, y_prob_val_1d)\n",
    "print(f\"Optimal threshold: {optimal_threshold_1d:.3f}\")\n",
    "print(f\"Best validation F1 score: {best_val_f1_1d:.4f}\")\n",
    "\n",
    "# Evaluate on test set with both thresholds\n",
    "y_prob_test_1d = final_model_1d.predict_proba(X_test_1d)[:, 1]\n",
    "\n",
    "print(\"\\nTest Set Results Comparison:\")\n",
    "metrics_default_1d, metrics_optimal_1d = evaluate_model_with_thresholds(\n",
    "    y_test_1d, y_prob_test_1d, 0.5, optimal_threshold_1d, \"1D_Up Prediction\")\n",
    "\n",
    "# 20D_Up prediction with threshold optimization\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"20D_Up Prediction Model with Threshold Optimization\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "X_train_20d, y_train_20d, X_val_20d, y_val_20d, X_test_20d, y_test_20d, scaler_20d = preprocess_data(\n",
    "    train_data, val_data, test_data, '20D_Up', continuous_features, binary_features)\n",
    "\n",
    "# TimeSeriesSplit cross-validation to select best regularization parameter\n",
    "grid_search_20d = GridSearchCV(\n",
    "    LogisticRegression(penalty='l1', solver='liblinear', random_state=42),\n",
    "    param_grid, cv=tscv, scoring='f1', n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_20d.fit(X_train_20d, y_train_20d)\n",
    "best_C_20d = grid_search_20d.best_params_['C']\n",
    "print(f\"Best regularization parameter C: {best_C_20d}\")\n",
    "\n",
    "# Train final model with best parameter\n",
    "final_model_20d = LogisticRegression(penalty='l1', solver='liblinear', C=best_C_20d, random_state=42)\n",
    "final_model_20d.fit(X_train_20d, y_train_20d)\n",
    "\n",
    "# Get validation set predictions for threshold optimization\n",
    "y_prob_val_20d = final_model_20d.predict_proba(X_val_20d)[:, 1]\n",
    "\n",
    "# Find optimal threshold on validation set\n",
    "print(\"\\nFinding optimal threshold on validation set...\")\n",
    "optimal_threshold_20d, best_val_f1_20d = find_optimal_threshold(y_val_20d, y_prob_val_20d)\n",
    "print(f\"Optimal threshold: {optimal_threshold_20d:.3f}\")\n",
    "print(f\"Best validation F1 score: {best_val_f1_20d:.4f}\")\n",
    "\n",
    "# Evaluate on test set with both thresholds\n",
    "y_prob_test_20d = final_model_20d.predict_proba(X_test_20d)[:, 1]\n",
    "\n",
    "print(\"\\nTest Set Results Comparison:\")\n",
    "metrics_default_20d, metrics_optimal_20d = evaluate_model_with_thresholds(\n",
    "    y_test_20d, y_prob_test_20d, 0.5, optimal_threshold_20d, \"20D_Up Prediction\")\n",
    "\n",
    "# Summary of improvements\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY OF THRESHOLD OPTIMIZATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n1D_Up Prediction:\")\n",
    "print(f\"  Default F1 (threshold=0.5): {metrics_default_1d['f1_binary']:.4f}\")\n",
    "print(f\"  Optimal F1 (threshold={optimal_threshold_1d:.3f}): {metrics_optimal_1d['f1_binary']:.4f}\")\n",
    "print(f\"  F1 Improvement: {metrics_optimal_1d['f1_binary'] - metrics_default_1d['f1_binary']:+.4f}\")\n",
    "\n",
    "print(f\"\\n20D_Up Prediction:\")\n",
    "print(f\"  Default F1 (threshold=0.5): {metrics_default_20d['f1_binary']:.4f}\")\n",
    "print(f\"  Optimal F1 (threshold={optimal_threshold_20d:.3f}): {metrics_optimal_20d['f1_binary']:.4f}\")\n",
    "print(f\"  F1 Improvement: {metrics_optimal_20d['f1_binary'] - metrics_default_20d['f1_binary']:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d8e83-9d97-4687-b362-894ee74eb1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coefficients(model, feature_names, model_name):\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    coefs = model.coef_[0]\n",
    "    coef_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefs})\n",
    "    coef_df = coef_df.sort_values(by='Coefficient', key=abs, ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, max(6, 0.4*len(coef_df))))\n",
    "    sns.barplot(x='Coefficient', y='Feature', data=coef_df, palette='coolwarm')\n",
    "    plt.axvline(0, color='gray', linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Optionally print table too\n",
    "    print(coef_df.to_string(index=False))\n",
    "plot_coefficients(final_model_1d, features, \"1D_Up Prediction\")\n",
    "plot_coefficients(final_model_20d, features, \"20D_Up Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b4e0e6-cc08-4958-83bc-f1a6a9fd94bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38d09b96-5ac2-46a6-bade-c26054921840",
   "metadata": {},
   "source": [
    "## Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb1733e-9cba-4824-bfc3-1aedf840e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('DATA.csv')\n",
    "\n",
    "# Define feature columns\n",
    "continuous_features = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct',  'J', \n",
    "                      'mfi', 'MACD', 'MACD_diff',  'BB_rel_pos', 'Vol_Change', 'Gold_Close']\n",
    "binary_features = ['MA5_GT_MA20']\n",
    "features = continuous_features + binary_features\n",
    "\n",
    "# Split data by company in chronological order\n",
    "train_data_list = []\n",
    "val_data_list = []\n",
    "test_data_list = []\n",
    "\n",
    "for company in df['Company'].unique():\n",
    "    company_data = df[df['Company'] == company].copy()\n",
    "    company_data = company_data.sort_values('Date')  \n",
    "    n_company = len(company_data)\n",
    "    train_size = int(0.7 * n_company)\n",
    "    val_size = int(0.15 * n_company)\n",
    "    \n",
    "    train_data_list.append(company_data.iloc[:train_size])\n",
    "    val_data_list.append(company_data.iloc[train_size:train_size+val_size])\n",
    "    test_data_list.append(company_data.iloc[train_size+val_size:])\n",
    "\n",
    "# Concatenate all companies' data\n",
    "train_data = pd.concat(train_data_list, ignore_index=True)\n",
    "val_data = pd.concat(val_data_list, ignore_index=True)\n",
    "test_data = pd.concat(test_data_list, ignore_index=True)\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")\n",
    "print(f\"Training set company distribution:\\n{train_data['Company'].value_counts().sort_index()}\")\n",
    "print(f\"Test set company distribution:\\n{test_data['Company'].value_counts().sort_index()}\")\n",
    "\n",
    "# Modified preprocessing function\n",
    "def preprocess_data(train_df, val_df, test_df, target_col, continuous_features, binary_features):\n",
    "    all_features = continuous_features + binary_features\n",
    "    \n",
    "    # Drop missing values\n",
    "    train_df = train_df.dropna(subset=all_features + [target_col])\n",
    "    val_df = val_df.dropna(subset=all_features + [target_col])\n",
    "    test_df = test_df.dropna(subset=all_features + [target_col])\n",
    "    \n",
    "    # Separate continuous and binary features\n",
    "    X_train_continuous = train_df[continuous_features]\n",
    "    X_val_continuous = val_df[continuous_features]\n",
    "    X_test_continuous = test_df[continuous_features]\n",
    "    \n",
    "    X_train_binary = train_df[binary_features]\n",
    "    X_val_binary = val_df[binary_features]\n",
    "    X_test_binary = test_df[binary_features]\n",
    "    \n",
    "    y_train = train_df[target_col]\n",
    "    y_val = val_df[target_col]\n",
    "    y_test = test_df[target_col]\n",
    "    \n",
    "    # Standardize only continuous features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_continuous_scaled = scaler.fit_transform(X_train_continuous)\n",
    "    X_val_continuous_scaled = scaler.transform(X_val_continuous)\n",
    "    X_test_continuous_scaled = scaler.transform(X_test_continuous)\n",
    "    \n",
    "    # Combine scaled continuous features with unscaled binary features\n",
    "    X_train_scaled = np.hstack([X_train_continuous_scaled, X_train_binary.values])\n",
    "    X_val_scaled = np.hstack([X_val_continuous_scaled, X_val_binary.values])\n",
    "    X_test_scaled = np.hstack([X_test_continuous_scaled, X_test_binary.values])\n",
    "    \n",
    "    return X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, scaler\n",
    "\n",
    "# NEW Evaluation function\n",
    "def evaluate_model(y_true, y_pred, y_prob, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Overall metrics\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    # Class-specific metrics\n",
    "    precision_per_class = precision_score(y_true, y_pred, average=None)\n",
    "    recall_per_class = recall_score(y_true, y_pred, average=None)\n",
    "    f1_per_class = f1_score(y_true, y_pred, average=None)\n",
    "    \n",
    "    # Confusion matrix heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance metrics table - NEW FORMAT\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.axis('tight')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    table_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Macro F1 Score', f'{f1_macro:.4f}'],\n",
    "        ['Overall Accuracy', f'{accuracy:.4f}'],\n",
    "        ['AUC', f'{auc:.4f}'],\n",
    "        ['', ''],  # Empty row for separation\n",
    "        ['Class 1 Precision', f'{precision_per_class[1]:.4f}'],\n",
    "        ['Class 1 Recall', f'{recall_per_class[1]:.4f}'],\n",
    "        ['Class 1 F1', f'{f1_per_class[1]:.4f}'],\n",
    "        ['', ''],  # Empty row for separation\n",
    "        ['Class 0 Precision', f'{precision_per_class[0]:.4f}'],\n",
    "        ['Class 0 Recall', f'{recall_per_class[0]:.4f}'],\n",
    "        ['Class 0 F1', f'{f1_per_class[0]:.4f}']\n",
    "    ]\n",
    "    \n",
    "    table = plt.table(cellText=table_data[1:], colLabels=table_data[0],\n",
    "                     cellLoc='center', loc='center',\n",
    "                     colWidths=[0.4, 0.3])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.5, 2)\n",
    "    \n",
    "    # Set table style\n",
    "    for i in range(len(table_data)):\n",
    "        for j in range(len(table_data[0])):\n",
    "            cell = table[(i, j)]\n",
    "            if i == 0:  # header\n",
    "                cell.set_facecolor('#4CAF50')\n",
    "                cell.set_text_props(weight='bold', color='white')\n",
    "            elif len(table_data[i]) > 0 and table_data[i][0] == '':  # empty rows\n",
    "                cell.set_facecolor('#ffffff')\n",
    "                cell.set_text_props(color='white')\n",
    "            else:\n",
    "                cell.set_facecolor('#f0f0f0')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return {'confusion_matrix': cm, 'f1_macro': f1_macro, 'accuracy': accuracy, 'auc': auc,\n",
    "            'class_0_precision': precision_per_class[0], 'class_0_recall': recall_per_class[0], 'class_0_f1': f1_per_class[0],\n",
    "            'class_1_precision': precision_per_class[1], 'class_1_recall': recall_per_class[1], 'class_1_f1': f1_per_class[1]}\n",
    "\n",
    "# 1D_Up prediction\n",
    "print(\"=\" * 50)\n",
    "print(\"1D_Up Prediction Model\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "X_train_1d, y_train_1d, X_val_1d, y_val_1d, X_test_1d, y_test_1d, scaler_1d = preprocess_data(\n",
    "    train_data, val_data, test_data, '1D_Up', continuous_features, binary_features)\n",
    "\n",
    "# TimeSeriesSplit cross-validation to select best regularization parameter\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid_search_1d = GridSearchCV(\n",
    "    LogisticRegression(penalty='l1', solver='liblinear', random_state=42),\n",
    "    param_grid, cv=tscv, scoring='f1', n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_1d.fit(X_train_1d, y_train_1d)\n",
    "best_C_1d = grid_search_1d.best_params_['C']\n",
    "print(f\"Best regularization parameter C: {best_C_1d}\")\n",
    "\n",
    "# Train final model with best parameter\n",
    "final_model_1d = LogisticRegression(penalty='l1', solver='liblinear', C=best_C_1d, random_state=42)\n",
    "final_model_1d.fit(X_train_1d, y_train_1d)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_1d = final_model_1d.predict(X_test_1d)\n",
    "y_prob_1d = final_model_1d.predict_proba(X_test_1d)[:, 1]\n",
    "\n",
    "print(\"\\nTest Set Results:\")\n",
    "results_1d = evaluate_model(y_test_1d, y_pred_1d, y_prob_1d, \"1D_Up Prediction\")\n",
    "\n",
    "# 20D_Up prediction\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"20D_Up Prediction Model\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "X_train_20d, y_train_20d, X_val_20d, y_val_20d, X_test_20d, y_test_20d, scaler_20d = preprocess_data(\n",
    "    train_data, val_data, test_data, '20D_Up', continuous_features, binary_features)\n",
    "\n",
    "# TimeSeriesSplit cross-validation to select best regularization parameter\n",
    "grid_search_20d = GridSearchCV(\n",
    "    LogisticRegression(penalty='l1', solver='liblinear', random_state=42),\n",
    "    param_grid, cv=tscv, scoring='f1', n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_20d.fit(X_train_20d, y_train_20d)\n",
    "best_C_20d = grid_search_20d.best_params_['C']\n",
    "print(f\"Best regularization parameter C: {best_C_20d}\")\n",
    "\n",
    "# Train final model with best parameter\n",
    "final_model_20d = LogisticRegression(penalty='l1', solver='liblinear', C=best_C_20d, random_state=42)\n",
    "final_model_20d.fit(X_train_20d, y_train_20d)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_20d = final_model_20d.predict(X_test_20d)\n",
    "y_prob_20d = final_model_20d.predict_proba(X_test_20d)[:, 1]\n",
    "\n",
    "print(\"\\nTest Set Results:\")\n",
    "results_20d = evaluate_model(y_test_20d, y_pred_20d, y_prob_20d, \"20D_Up Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200a585b-b347-4ca0-a8a9-77571e7b71aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coefficients(model, feature_names, model_name):\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    coefs = model.coef_[0]\n",
    "    coef_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefs})\n",
    "    coef_df = coef_df.sort_values(by='Coefficient', key=abs, ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, max(6, 0.4*len(coef_df))))\n",
    "    sns.barplot(x='Coefficient', y='Feature', data=coef_df, palette='coolwarm')\n",
    "    plt.axvline(0, color='gray', linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Optionally print table too\n",
    "    print(coef_df.to_string(index=False))\n",
    "plot_coefficients(final_model_1d, features, \"1D_Up Prediction\")\n",
    "plot_coefficients(final_model_20d, features, \"20D_Up Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc1aa2f-bc8e-4996-825f-763724d2122b",
   "metadata": {},
   "source": [
    "## add interest rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e9afe6-d58b-449f-b475-0ee226008e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('DATA.csv')\n",
    "\n",
    "# Define feature columns\n",
    "continuous_features = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct',  'J', \n",
    "                      'mfi', 'MACD', 'MACD_diff', 'BB_rel_pos', 'Vol_Change', 'Interest_Rate']\n",
    "binary_features = ['MA5_GT_MA20']\n",
    "features = continuous_features + binary_features\n",
    "\n",
    "# Split data by company in chronological order\n",
    "train_data_list = []\n",
    "val_data_list = []\n",
    "test_data_list = []\n",
    "\n",
    "for company in df['Company'].unique():\n",
    "    company_data = df[df['Company'] == company].copy()\n",
    "    company_data = company_data.sort_values('Date')  \n",
    "    \n",
    "    n_company = len(company_data)\n",
    "    train_size = int(0.7 * n_company)\n",
    "    val_size = int(0.15 * n_company)\n",
    "    \n",
    "    train_data_list.append(company_data.iloc[:train_size])\n",
    "    val_data_list.append(company_data.iloc[train_size:train_size+val_size])\n",
    "    test_data_list.append(company_data.iloc[train_size+val_size:])\n",
    "\n",
    "# Concatenate all companies' data\n",
    "train_data = pd.concat(train_data_list, ignore_index=True)\n",
    "val_data = pd.concat(val_data_list, ignore_index=True)\n",
    "test_data = pd.concat(test_data_list, ignore_index=True)\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")\n",
    "print(f\"Training set company distribution:\\n{train_data['Company'].value_counts().sort_index()}\")\n",
    "print(f\"Test set company distribution:\\n{test_data['Company'].value_counts().sort_index()}\")\n",
    "\n",
    "# Modified preprocessing function\n",
    "def preprocess_data(train_df, val_df, test_df, target_col, continuous_features, binary_features):\n",
    "    all_features = continuous_features + binary_features\n",
    "    \n",
    "    # Drop missing values\n",
    "    train_df = train_df.dropna(subset=all_features + [target_col])\n",
    "    val_df = val_df.dropna(subset=all_features + [target_col])\n",
    "    test_df = test_df.dropna(subset=all_features + [target_col])\n",
    "    \n",
    "    # Separate continuous and binary features\n",
    "    X_train_continuous = train_df[continuous_features]\n",
    "    X_val_continuous = val_df[continuous_features]\n",
    "    X_test_continuous = test_df[continuous_features]\n",
    "    \n",
    "    X_train_binary = train_df[binary_features]\n",
    "    X_val_binary = val_df[binary_features]\n",
    "    X_test_binary = test_df[binary_features]\n",
    "    \n",
    "    y_train = train_df[target_col]\n",
    "    y_val = val_df[target_col]\n",
    "    y_test = test_df[target_col]\n",
    "    \n",
    "    # Standardize only continuous features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_continuous_scaled = scaler.fit_transform(X_train_continuous)\n",
    "    X_val_continuous_scaled = scaler.transform(X_val_continuous)\n",
    "    X_test_continuous_scaled = scaler.transform(X_test_continuous)\n",
    "    \n",
    "    # Combine scaled continuous features with unscaled binary features\n",
    "    X_train_scaled = np.hstack([X_train_continuous_scaled, X_train_binary.values])\n",
    "    X_val_scaled = np.hstack([X_val_continuous_scaled, X_val_binary.values])\n",
    "    X_test_scaled = np.hstack([X_test_continuous_scaled, X_test_binary.values])\n",
    "    \n",
    "    return X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, scaler\n",
    "\n",
    "# Evaluation function - NEW VERSION\n",
    "def evaluate_model(y_true, y_pred, y_prob, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Overall metrics\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    # Class-specific metrics\n",
    "    precision_per_class = precision_score(y_true, y_pred, average=None)\n",
    "    recall_per_class = recall_score(y_true, y_pred, average=None)\n",
    "    f1_per_class = f1_score(y_true, y_pred, average=None)\n",
    "    \n",
    "    # Confusion matrix heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance metrics table - NEW FORMAT\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.axis('tight')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    table_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Macro F1 Score', f'{f1_macro:.4f}'],\n",
    "        ['Overall Accuracy', f'{accuracy:.4f}'],\n",
    "        ['AUC', f'{auc:.4f}'],\n",
    "        ['', ''],  # Empty row for separation\n",
    "        ['Class 1 Precision', f'{precision_per_class[1]:.4f}'],\n",
    "        ['Class 1 Recall', f'{recall_per_class[1]:.4f}'],\n",
    "        ['Class 1 F1', f'{f1_per_class[1]:.4f}'],\n",
    "        ['', ''],  # Empty row for separation\n",
    "        ['Class 0 Precision', f'{precision_per_class[0]:.4f}'],\n",
    "        ['Class 0 Recall', f'{recall_per_class[0]:.4f}'],\n",
    "        ['Class 0 F1', f'{f1_per_class[0]:.4f}']\n",
    "    ]\n",
    "    \n",
    "    table = plt.table(cellText=table_data[1:], colLabels=table_data[0],\n",
    "                     cellLoc='center', loc='center',\n",
    "                     colWidths=[0.4, 0.3])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.5, 2)\n",
    "    \n",
    "    # Set table style\n",
    "    for i in range(len(table_data)):\n",
    "        for j in range(len(table_data[0])):\n",
    "            cell = table[(i, j)]\n",
    "            if i == 0:  # header\n",
    "                cell.set_facecolor('#4CAF50')\n",
    "                cell.set_text_props(weight='bold', color='white')\n",
    "            elif len(table_data[i]) > 0 and table_data[i][0] == '':  # empty rows\n",
    "                cell.set_facecolor('#ffffff')\n",
    "                cell.set_text_props(color='white')\n",
    "            else:\n",
    "                cell.set_facecolor('#f0f0f0')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return {'confusion_matrix': cm, 'f1_macro': f1_macro, 'accuracy': accuracy, 'auc': auc,\n",
    "            'class_0_precision': precision_per_class[0], 'class_0_recall': recall_per_class[0], 'class_0_f1': f1_per_class[0],\n",
    "            'class_1_precision': precision_per_class[1], 'class_1_recall': recall_per_class[1], 'class_1_f1': f1_per_class[1]}\n",
    "\n",
    "# 1D_Up prediction\n",
    "print(\"=\" * 50)\n",
    "print(\"1D_Up Prediction Model\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "X_train_1d, y_train_1d, X_val_1d, y_val_1d, X_test_1d, y_test_1d, scaler_1d = preprocess_data(\n",
    "    train_data, val_data, test_data, '1D_Up', continuous_features, binary_features)\n",
    "\n",
    "# TimeSeriesSplit cross-validation to select best regularization parameter\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid_search_1d = GridSearchCV(\n",
    "    LogisticRegression(penalty='l1', solver='liblinear', random_state=42),\n",
    "    param_grid, cv=tscv, scoring='f1', n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_1d.fit(X_train_1d, y_train_1d)\n",
    "best_C_1d = grid_search_1d.best_params_['C']\n",
    "print(f\"Best regularization parameter C: {best_C_1d}\")\n",
    "\n",
    "# Train final model with best parameter\n",
    "final_model_1d = LogisticRegression(penalty='l1', solver='liblinear', C=best_C_1d, random_state=42)\n",
    "final_model_1d.fit(X_train_1d, y_train_1d)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_1d = final_model_1d.predict(X_test_1d)\n",
    "y_prob_1d = final_model_1d.predict_proba(X_test_1d)[:, 1]\n",
    "\n",
    "print(\"\\nTest Set Results:\")\n",
    "results_1d = evaluate_model(y_test_1d, y_pred_1d, y_prob_1d, \"1D_Up Prediction\")\n",
    "\n",
    "# 20D_Up prediction\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"20D_Up Prediction Model\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "X_train_20d, y_train_20d, X_val_20d, y_val_20d, X_test_20d, y_test_20d, scaler_20d = preprocess_data(\n",
    "    train_data, val_data, test_data, '20D_Up', continuous_features, binary_features)\n",
    "\n",
    "# TimeSeriesSplit cross-validation to select best regularization parameter\n",
    "grid_search_20d = GridSearchCV(\n",
    "    LogisticRegression(penalty='l1', solver='liblinear', random_state=42),\n",
    "    param_grid, cv=tscv, scoring='f1', n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_20d.fit(X_train_20d, y_train_20d)\n",
    "best_C_20d = grid_search_20d.best_params_['C']\n",
    "print(f\"Best regularization parameter C: {best_C_20d}\")\n",
    "\n",
    "# Train final model with best parameter\n",
    "final_model_20d = LogisticRegression(penalty='l1', solver='liblinear', C=best_C_20d, random_state=42)\n",
    "final_model_20d.fit(X_train_20d, y_train_20d)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_20d = final_model_20d.predict(X_test_20d)\n",
    "y_prob_20d = final_model_20d.predict_proba(X_test_20d)[:, 1]\n",
    "\n",
    "print(\"\\nTest Set Results:\")\n",
    "results_20d = evaluate_model(y_test_20d, y_pred_20d, y_prob_20d, \"20D_Up Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4daf393-5ce7-4434-a6da-86a678ba06a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coefficients(model, feature_names, model_name):\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    coefs = model.coef_[0]\n",
    "    coef_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefs})\n",
    "    coef_df = coef_df.sort_values(by='Coefficient', key=abs, ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, max(6, 0.4*len(coef_df))))\n",
    "    sns.barplot(x='Coefficient', y='Feature', data=coef_df, palette='coolwarm')\n",
    "    plt.axvline(0, color='gray', linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Optionally print table too\n",
    "    print(coef_df.to_string(index=False))\n",
    "plot_coefficients(final_model_1d, features, \"1D_Up Prediction\")\n",
    "plot_coefficients(final_model_20d, features, \"20D_Up Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836a048c-821e-48a4-a6d2-b1f92b4ec2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59ab7c5-f388-41f0-aa3b-31f58a40dec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
