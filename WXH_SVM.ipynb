{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1154d8b3-d446-4b7b-9fb6-0d75b3b09079",
   "metadata": {},
   "source": [
    "## BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b91293-f5b2-4cc6-b0ba-11bffd997e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('DATA.csv')\n",
    "\n",
    "# Define feature columns - Baseline model (only technical indicators)\n",
    "continuous_features = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct',  'J', \n",
    "                      'mfi', 'MACD', 'MACD_diff',  'BB_rel_pos', 'Vol_Change']\n",
    "binary_features = ['MA5_GT_MA20']\n",
    "features = continuous_features + binary_features\n",
    "\n",
    "# Split data by company in chronological order\n",
    "train_data_list = []\n",
    "val_data_list = []\n",
    "test_data_list = []\n",
    "\n",
    "for company in df['Company'].unique():\n",
    "    company_data = df[df['Company'] == company].copy()\n",
    "    company_data = company_data.sort_values('Date')  \n",
    "    \n",
    "    n_company = len(company_data)\n",
    "    train_size = int(0.7 * n_company)\n",
    "    val_size = int(0.15 * n_company)\n",
    "    \n",
    "    train_data_list.append(company_data.iloc[:train_size])\n",
    "    val_data_list.append(company_data.iloc[train_size:train_size+val_size])\n",
    "    test_data_list.append(company_data.iloc[train_size+val_size:])\n",
    "\n",
    "# Concatenate all companies' data\n",
    "train_data = pd.concat(train_data_list, ignore_index=True)\n",
    "val_data = pd.concat(val_data_list, ignore_index=True)\n",
    "test_data = pd.concat(test_data_list, ignore_index=True)\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Validation set size: {len(val_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")\n",
    "print(f\"Training set company distribution:\\n{train_data['Company'].value_counts().sort_index()}\")\n",
    "print(f\"Test set company distribution:\\n{test_data['Company'].value_counts().sort_index()}\")\n",
    "\n",
    "# Modified preprocessing function\n",
    "def preprocess_data(train_df, val_df, test_df, target_col, continuous_features, binary_features):\n",
    "    all_features = continuous_features + binary_features\n",
    "    \n",
    "    # Drop missing values\n",
    "    train_df = train_df.dropna(subset=all_features + [target_col])\n",
    "    val_df = val_df.dropna(subset=all_features + [target_col])\n",
    "    test_df = test_df.dropna(subset=all_features + [target_col])\n",
    "    \n",
    "    # Separate continuous and binary features\n",
    "    X_train_continuous = train_df[continuous_features]\n",
    "    X_val_continuous = val_df[continuous_features]\n",
    "    X_test_continuous = test_df[continuous_features]\n",
    "    \n",
    "    X_train_binary = train_df[binary_features]\n",
    "    X_val_binary = val_df[binary_features]\n",
    "    X_test_binary = test_df[binary_features]\n",
    "    \n",
    "    y_train = train_df[target_col]\n",
    "    y_val = val_df[target_col]\n",
    "    y_test = test_df[target_col]\n",
    "    \n",
    "    # Standardize only continuous features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_continuous_scaled = scaler.fit_transform(X_train_continuous)\n",
    "    X_val_continuous_scaled = scaler.transform(X_val_continuous)\n",
    "    X_test_continuous_scaled = scaler.transform(X_test_continuous)\n",
    "    \n",
    "    # Combine scaled continuous features with unscaled binary features\n",
    "    X_train_scaled = np.hstack([X_train_continuous_scaled, X_train_binary.values])\n",
    "    X_val_scaled = np.hstack([X_val_continuous_scaled, X_val_binary.values])\n",
    "    X_test_scaled = np.hstack([X_test_continuous_scaled, X_test_binary.values])\n",
    "    \n",
    "    return X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, scaler\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(y_true, y_pred, y_prob, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Overall metrics\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    # Class-specific metrics\n",
    "    precision_per_class = precision_score(y_true, y_pred, average=None)\n",
    "    recall_per_class = recall_score(y_true, y_pred, average=None)\n",
    "    f1_per_class = f1_score(y_true, y_pred, average=None)\n",
    "    \n",
    "    # Confusion matrix heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.title(f'{model_name} SVM L1 - Confusion Matrix')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance metrics table\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.axis('tight')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    table_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Macro F1 Score', f'{f1_macro:.4f}'],\n",
    "        ['Overall Accuracy', f'{accuracy:.4f}'],\n",
    "        ['AUC', f'{auc:.4f}'],\n",
    "        ['', ''],  # Empty row for separation\n",
    "        ['Class 1 Precision', f'{precision_per_class[1]:.4f}'],\n",
    "        ['Class 1 Recall', f'{recall_per_class[1]:.4f}'],\n",
    "        ['Class 1 F1', f'{f1_per_class[1]:.4f}'],\n",
    "        ['', ''],  # Empty row for separation\n",
    "        ['Class 0 Precision', f'{precision_per_class[0]:.4f}'],\n",
    "        ['Class 0 Recall', f'{recall_per_class[0]:.4f}'],\n",
    "        ['Class 0 F1', f'{f1_per_class[0]:.4f}']\n",
    "    ]\n",
    "    \n",
    "    table = plt.table(cellText=table_data[1:], colLabels=table_data[0],\n",
    "                     cellLoc='center', loc='center',\n",
    "                     colWidths=[0.4, 0.3])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1.5, 2)\n",
    "    \n",
    "    # Set table style\n",
    "    for i in range(len(table_data)):\n",
    "        for j in range(len(table_data[0])):\n",
    "            cell = table[(i, j)]\n",
    "            if i == 0:  # header\n",
    "                cell.set_facecolor('#4CAF50')\n",
    "                cell.set_text_props(weight='bold', color='white')\n",
    "            elif len(table_data[i]) > 0 and table_data[i][0] == '':  # empty rows\n",
    "                cell.set_facecolor('#ffffff')\n",
    "                cell.set_text_props(color='white')\n",
    "            else:\n",
    "                cell.set_facecolor('#f0f0f0')\n",
    "    \n",
    "    plt.title(f'{model_name} SVM L1 - Performance Metrics', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.show()\n",
    "    \n",
    "    return {'confusion_matrix': cm, 'f1_macro': f1_macro, 'accuracy': accuracy, 'auc': auc,\n",
    "            'class_0_precision': precision_per_class[0], 'class_0_recall': recall_per_class[0], 'class_0_f1': f1_per_class[0],\n",
    "            'class_1_precision': precision_per_class[1], 'class_1_recall': recall_per_class[1], 'class_1_f1': f1_per_class[1]}\n",
    "\n",
    "# 1D_Up prediction\n",
    "print(\"=\" * 60)\n",
    "print(\"1D_Up Prediction Model - SVM with L1 Regularization (Baseline)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "X_train_1d, y_train_1d, X_val_1d, y_val_1d, X_test_1d, y_test_1d, scaler_1d = preprocess_data(\n",
    "    train_data, val_data, test_data, '1D_Up', continuous_features, binary_features)\n",
    "\n",
    "# TimeSeriesSplit cross-validation for SVM hyperparameters\n",
    "# Optimized for 3000 rows of data\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],           \n",
    "    'class_weight': [None, 'balanced'],      \n",
    "    'max_iter': [10000]                      \n",
    "}\n",
    "\n",
    "print(\"Starting hyperparameter tuning for 1D SVM model...\")\n",
    "grid_search_1d = GridSearchCV(\n",
    "    LinearSVC(penalty='l1', dual=False, random_state=42),  \n",
    "    param_grid, cv=tscv, scoring='f1', n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "grid_search_1d.fit(X_train_1d, y_train_1d)\n",
    "best_params_1d = grid_search_1d.best_params_\n",
    "print(f\"Best parameters for 1D model: {best_params_1d}\")\n",
    "print(f\"Best cross-validation F1 score: {grid_search_1d.best_score_:.4f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "final_svm_1d = LinearSVC(penalty='l1', dual=False, random_state=42, **best_params_1d)\n",
    "final_svm_1d.fit(X_train_1d, y_train_1d)\n",
    "\n",
    "# Use CalibratedClassifierCV to get probability estimates\n",
    "calibrated_svm_1d = CalibratedClassifierCV(final_svm_1d, cv=3)\n",
    "calibrated_svm_1d.fit(X_train_1d, y_train_1d)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_1d = calibrated_svm_1d.predict(X_test_1d)\n",
    "y_prob_1d = calibrated_svm_1d.predict_proba(X_test_1d)[:, 1]\n",
    "\n",
    "print(\"\\n1D Model Test Set Results:\")\n",
    "results_1d = evaluate_model(y_test_1d, y_pred_1d, y_prob_1d, \"1D_Up Prediction\")\n",
    "\n",
    "# 20D_Up prediction\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"20D_Up Prediction Model - SVM with L1 Regularization (Baseline)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "X_train_20d, y_train_20d, X_val_20d, y_val_20d, X_test_20d, y_test_20d, scaler_20d = preprocess_data(\n",
    "    train_data, val_data, test_data, '20D_Up', continuous_features, binary_features)\n",
    "\n",
    "print(\"Starting hyperparameter tuning for 20D SVM model...\")\n",
    "grid_search_20d = GridSearchCV(\n",
    "    LinearSVC(penalty='l1', dual=False, random_state=42),\n",
    "    param_grid, cv=tscv, scoring='f1', n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "grid_search_20d.fit(X_train_20d, y_train_20d)\n",
    "best_params_20d = grid_search_20d.best_params_\n",
    "print(f\"Best parameters for 20D model: {best_params_20d}\")\n",
    "print(f\"Best cross-validation F1 score: {grid_search_20d.best_score_:.4f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "final_svm_20d = LinearSVC(penalty='l1', dual=False, random_state=42, **best_params_20d)\n",
    "final_svm_20d.fit(X_train_20d, y_train_20d)\n",
    "\n",
    "# Use CalibratedClassifierCV to get probability estimates\n",
    "calibrated_svm_20d = CalibratedClassifierCV(final_svm_20d, cv=3)\n",
    "calibrated_svm_20d.fit(X_train_20d, y_train_20d)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_20d = calibrated_svm_20d.predict(X_test_20d)\n",
    "y_prob_20d = calibrated_svm_20d.predict_proba(X_test_20d)[:, 1]\n",
    "\n",
    "print(\"\\n20D Model Test Set Results:\")\n",
    "results_20d = evaluate_model(y_test_20d, y_pred_20d, y_prob_20d, \"20D_Up Prediction\")\n",
    "\n",
    "# Feature Coefficients Analysis\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Feature Coefficients Analysis - SVM L1 Baseline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = continuous_features + binary_features\n",
    "\n",
    "# Get coefficients from both models\n",
    "coef_1d = final_svm_1d.coef_[0]\n",
    "coef_20d = final_svm_20d.coef_[0]\n",
    "avg_coef = (coef_1d + coef_20d) / 2\n",
    "\n",
    "# Create coefficients dataframe\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    '1D_Model': coef_1d,\n",
    "    '20D_Model': coef_20d,\n",
    "    'Average': avg_coef,\n",
    "    'Abs_Average': np.abs(avg_coef)\n",
    "}).sort_values('Abs_Average', ascending=True)\n",
    "\n",
    "# Plot feature coefficients\n",
    "plt.figure(figsize=(12, 8))\n",
    "y_pos = np.arange(len(feature_names))\n",
    "\n",
    "# Color bars based on positive/negative coefficients\n",
    "colors = ['red' if coef < 0 else 'blue' for coef in coef_df['Average']]\n",
    "bars = plt.barh(y_pos, coef_df['Average'], color=colors, alpha=0.7)\n",
    "\n",
    "# Customize the plot\n",
    "plt.yticks(y_pos, coef_df['Feature'])\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.title('SVM L1 Feature Coefficients - Baseline Model\\n(Red: Negative, Blue: Positive)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "plt.axvline(x=0, color='black', linestyle='-', alpha=0.5)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + (0.01 if width >= 0 else -0.01), bar.get_y() + bar.get_height()/2, \n",
    "             f'{width:.3f}', ha='left' if width >= 0 else 'right', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print coefficients summary\n",
    "print(f\"\\nFeature Coefficients Summary:\")\n",
    "print(f\"Total features: {len(feature_names)}\")\n",
    "\n",
    "# Features with zero coefficients (due to L1 regularization)\n",
    "zero_coef_features = coef_df[coef_df['Abs_Average'] < 1e-6]['Feature'].tolist()\n",
    "non_zero_features = len(feature_names) - len(zero_coef_features)\n",
    "\n",
    "print(f\"Non-zero coefficients: {non_zero_features}/{len(feature_names)}\")\n",
    "if zero_coef_features:\n",
    "    print(f\"Features with zero coefficients (selected out by L1): {zero_coef_features}\")\n",
    "\n",
    "print(f\"\\nLargest positive coefficient: {coef_df.iloc[-1]['Feature']} ({coef_df.iloc[-1]['Average']:.4f})\")\n",
    "print(f\"Largest negative coefficient: {coef_df.iloc[0]['Feature']} ({coef_df.iloc[0]['Average']:.4f})\")\n",
    "\n",
    "print(\"\\nTop 10 Features by Absolute Coefficient Value:\")\n",
    "top_coef = coef_df.tail(10)[['Feature', 'Average', 'Abs_Average']].copy()\n",
    "top_coef['Rank'] = range(len(top_coef), 0, -1)\n",
    "print(top_coef[['Rank', 'Feature', 'Average']].to_string(index=False))\n",
    "\n",
    "# Model comparison summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Model Performance Summary\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"1D Model Performance:\")\n",
    "print(f\"  - Macro F1 Score: {results_1d['f1_macro']:.4f}\")\n",
    "print(f\"  - Overall Accuracy: {results_1d['accuracy']:.4f}\")\n",
    "print(f\"  - AUC: {results_1d['auc']:.4f}\")\n",
    "\n",
    "print(f\"\\n20D Model Performance:\")\n",
    "print(f\"  - Macro F1 Score: {results_20d['f1_macro']:.4f}\")\n",
    "print(f\"  - Overall Accuracy: {results_20d['accuracy']:.4f}\")\n",
    "print(f\"  - AUC: {results_20d['auc']:.4f}\")\n",
    "\n",
    "# Calculate average performance\n",
    "avg_f1 = (results_1d['f1_macro'] + results_20d['f1_macro']) / 2\n",
    "avg_accuracy = (results_1d['accuracy'] + results_20d['accuracy']) / 2\n",
    "avg_auc = (results_1d['auc'] + results_20d['auc']) / 2\n",
    "\n",
    "print(f\"\\nAverage Performance Across Both Models:\")\n",
    "print(f\"  - Average Macro F1 Score: {avg_f1:.4f}\")\n",
    "print(f\"  - Average Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"  - Average AUC: {avg_auc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SVM L1 Baseline Model Analysis Complete!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd50d8dd-25c1-4e7e-b68b-7789315014fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db732e28-0f73-4044-805d-5581669bdea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "def run_svm_model(df, continuous_features, binary_features, model_name, title_suffix):\n",
    "    \"\"\"Generic SVM L1 regularization model training and evaluation function\"\"\"\n",
    "    \n",
    "    # Data splitting\n",
    "    train_data_list = []\n",
    "    val_data_list = []\n",
    "    test_data_list = []\n",
    "\n",
    "    for company in df['Company'].unique():\n",
    "        company_data = df[df['Company'] == company].copy()\n",
    "        company_data = company_data.sort_values('Date')\n",
    "        \n",
    "        n_company = len(company_data)\n",
    "        train_size = int(0.7 * n_company)\n",
    "        val_size = int(0.15 * n_company)\n",
    "        \n",
    "        train_data_list.append(company_data.iloc[:train_size])\n",
    "        val_data_list.append(company_data.iloc[train_size:train_size+val_size])\n",
    "        test_data_list.append(company_data.iloc[train_size+val_size:])\n",
    "\n",
    "    train_data = pd.concat(train_data_list, ignore_index=True)\n",
    "    val_data = pd.concat(val_data_list, ignore_index=True)\n",
    "    test_data = pd.concat(test_data_list, ignore_index=True)\n",
    "\n",
    "    print(f\"Training set size: {len(train_data)}\")\n",
    "    print(f\"Validation set size: {len(val_data)}\")\n",
    "    print(f\"Test set size: {len(test_data)}\")\n",
    "    \n",
    "    # Data preprocessing\n",
    "    def preprocess_data(train_df, val_df, test_df, target_col, continuous_features, binary_features):\n",
    "        all_features = continuous_features + binary_features\n",
    "        \n",
    "        train_df = train_df.dropna(subset=all_features + [target_col])\n",
    "        val_df = val_df.dropna(subset=all_features + [target_col])\n",
    "        test_df = test_df.dropna(subset=all_features + [target_col])\n",
    "        \n",
    "        X_train_continuous = train_df[continuous_features]\n",
    "        X_val_continuous = val_df[continuous_features]\n",
    "        X_test_continuous = test_df[continuous_features]\n",
    "        \n",
    "        X_train_binary = train_df[binary_features]\n",
    "        X_val_binary = val_df[binary_features]\n",
    "        X_test_binary = test_df[binary_features]\n",
    "        \n",
    "        y_train = train_df[target_col]\n",
    "        y_val = val_df[target_col]\n",
    "        y_test = test_df[target_col]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_continuous_scaled = scaler.fit_transform(X_train_continuous)\n",
    "        X_val_continuous_scaled = scaler.transform(X_val_continuous)\n",
    "        X_test_continuous_scaled = scaler.transform(X_test_continuous)\n",
    "        \n",
    "        X_train_scaled = np.hstack([X_train_continuous_scaled, X_train_binary.values])\n",
    "        X_val_scaled = np.hstack([X_val_continuous_scaled, X_val_binary.values])\n",
    "        X_test_scaled = np.hstack([X_test_continuous_scaled, X_test_binary.values])\n",
    "        \n",
    "        return X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, scaler\n",
    "\n",
    "    def evaluate_model(y_true, y_pred, y_prob, model_name):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        auc = roc_auc_score(y_true, y_prob)\n",
    "        precision_per_class = precision_score(y_true, y_pred, average=None)\n",
    "        recall_per_class = recall_score(y_true, y_pred, average=None)\n",
    "        f1_per_class = f1_score(y_true, y_pred, average=None)\n",
    "        \n",
    "        # Confusion matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                    yticklabels=['Actual 0', 'Actual 1'])\n",
    "        plt.title(f'{model_name} SVM L1 {title_suffix} - Confusion Matrix')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.show()\n",
    "        \n",
    "        # Performance metrics table\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.axis('tight')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        table_data = [\n",
    "            ['Metric', 'Value'],\n",
    "            ['Macro F1 Score', f'{f1_macro:.4f}'],\n",
    "            ['Overall Accuracy', f'{accuracy:.4f}'],\n",
    "            ['AUC', f'{auc:.4f}'],\n",
    "            ['', ''],\n",
    "            ['Class 1 Precision', f'{precision_per_class[1]:.4f}'],\n",
    "            ['Class 1 Recall', f'{recall_per_class[1]:.4f}'],\n",
    "            ['Class 1 F1', f'{f1_per_class[1]:.4f}'],\n",
    "            ['', ''],\n",
    "            ['Class 0 Precision', f'{precision_per_class[0]:.4f}'],\n",
    "            ['Class 0 Recall', f'{recall_per_class[0]:.4f}'],\n",
    "            ['Class 0 F1', f'{f1_per_class[0]:.4f}']\n",
    "        ]\n",
    "        \n",
    "        table = plt.table(cellText=table_data[1:], colLabels=table_data[0],\n",
    "                         cellLoc='center', loc='center', colWidths=[0.4, 0.3])\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(12)\n",
    "        table.scale(1.5, 2)\n",
    "        \n",
    "        for i in range(len(table_data)):\n",
    "            for j in range(len(table_data[0])):\n",
    "                cell = table[(i, j)]\n",
    "                if i == 0:\n",
    "                    cell.set_facecolor('#4CAF50')\n",
    "                    cell.set_text_props(weight='bold', color='white')\n",
    "                elif len(table_data[i]) > 0 and table_data[i][0] == '':\n",
    "                    cell.set_facecolor('#ffffff')\n",
    "                    cell.set_text_props(color='white')\n",
    "                else:\n",
    "                    cell.set_facecolor('#f0f0f0')\n",
    "        \n",
    "        plt.title(f'{model_name} SVM L1 {title_suffix} - Performance Metrics', fontsize=16, fontweight='bold', pad=20)\n",
    "        plt.show()\n",
    "        \n",
    "        return {'confusion_matrix': cm, 'f1_macro': f1_macro, 'accuracy': accuracy, 'auc': auc,\n",
    "                'class_0_precision': precision_per_class[0], 'class_0_recall': recall_per_class[0], 'class_0_f1': f1_per_class[0],\n",
    "                'class_1_precision': precision_per_class[1], 'class_1_recall': recall_per_class[1], 'class_1_f1': f1_per_class[1]}\n",
    "\n",
    "    # Model training\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"SVM L1 {model_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # SVM hyperparameter grid\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'class_weight': [None, 'balanced'],\n",
    "        'max_iter': [10000]\n",
    "    }\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    # 1D model\n",
    "    X_train_1d, y_train_1d, X_val_1d, y_val_1d, X_test_1d, y_test_1d, scaler_1d = preprocess_data(\n",
    "        train_data, val_data, test_data, '1D_Up', continuous_features, binary_features)\n",
    "    \n",
    "    print(\"Training 1D SVM model...\")\n",
    "    grid_search_1d = GridSearchCV(\n",
    "        LinearSVC(penalty='l1', dual=False, random_state=42),\n",
    "        param_grid, cv=tscv, scoring='f1', n_jobs=-1, verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search_1d.fit(X_train_1d, y_train_1d)\n",
    "    best_params_1d = grid_search_1d.best_params_\n",
    "    print(f\"Best parameters 1D: {best_params_1d}\")\n",
    "    \n",
    "    final_svm_1d = LinearSVC(penalty='l1', dual=False, random_state=42, **best_params_1d)\n",
    "    final_svm_1d.fit(X_train_1d, y_train_1d)\n",
    "    \n",
    "    calibrated_svm_1d = CalibratedClassifierCV(final_svm_1d, cv=3)\n",
    "    calibrated_svm_1d.fit(X_train_1d, y_train_1d)\n",
    "    \n",
    "    y_pred_1d = calibrated_svm_1d.predict(X_test_1d)\n",
    "    y_prob_1d = calibrated_svm_1d.predict_proba(X_test_1d)[:, 1]\n",
    "    \n",
    "    results_1d = evaluate_model(y_test_1d, y_pred_1d, y_prob_1d, \"1D_Up Prediction\")\n",
    "    \n",
    "    # 20D model\n",
    "    X_train_20d, y_train_20d, X_val_20d, y_val_20d, X_test_20d, y_test_20d, scaler_20d = preprocess_data(\n",
    "        train_data, val_data, test_data, '20D_Up', continuous_features, binary_features)\n",
    "    \n",
    "    print(\"Training 20D SVM model...\")\n",
    "    grid_search_20d = GridSearchCV(\n",
    "        LinearSVC(penalty='l1', dual=False, random_state=42),\n",
    "        param_grid, cv=tscv, scoring='f1', n_jobs=-1, verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search_20d.fit(X_train_20d, y_train_20d)\n",
    "    best_params_20d = grid_search_20d.best_params_\n",
    "    print(f\"Best parameters 20D: {best_params_20d}\")\n",
    "    \n",
    "    final_svm_20d = LinearSVC(penalty='l1', dual=False, random_state=42, **best_params_20d)\n",
    "    final_svm_20d.fit(X_train_20d, y_train_20d)\n",
    "    \n",
    "    calibrated_svm_20d = CalibratedClassifierCV(final_svm_20d, cv=3)\n",
    "    calibrated_svm_20d.fit(X_train_20d, y_train_20d)\n",
    "    \n",
    "    y_pred_20d = calibrated_svm_20d.predict(X_test_20d)\n",
    "    y_prob_20d = calibrated_svm_20d.predict_proba(X_test_20d)[:, 1]\n",
    "    \n",
    "    results_20d = evaluate_model(y_test_20d, y_pred_20d, y_prob_20d, \"20D_Up Prediction\")\n",
    "    \n",
    "    # Coefficient analysis\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Feature Coefficients Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    feature_names = continuous_features + binary_features\n",
    "    coef_1d = final_svm_1d.coef_[0]\n",
    "    coef_20d = final_svm_20d.coef_[0]\n",
    "    avg_coef = (coef_1d + coef_20d) / 2\n",
    "    \n",
    "    coef_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        '1D_Model': coef_1d,\n",
    "        '20D_Model': coef_20d,\n",
    "        'Average': avg_coef,\n",
    "        'Abs_Average': np.abs(avg_coef)\n",
    "    }).sort_values('Abs_Average', ascending=True)\n",
    "    \n",
    "    plt.figure(figsize=(12, max(8, len(feature_names)*0.4)))\n",
    "    y_pos = np.arange(len(feature_names))\n",
    "    \n",
    "    colors = ['red' if coef < 0 else 'blue' for coef in coef_df['Average']]\n",
    "    bars = plt.barh(y_pos, coef_df['Average'], color=colors, alpha=0.7)\n",
    "    \n",
    "    plt.yticks(y_pos, coef_df['Feature'])\n",
    "    plt.xlabel('Coefficient Value')\n",
    "    plt.title(f'SVM L1 Feature Coefficients - {model_name}\\n(Red: Negative, Blue: Positive)')\n",
    "    plt.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "    plt.axvline(x=0, color='black', linestyle='-', alpha=0.5)\n",
    "    \n",
    "    for i, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        plt.text(width + (0.01 if width >= 0 else -0.01), bar.get_y() + bar.get_height()/2, \n",
    "                 f'{width:.3f}', ha='left' if width >= 0 else 'right', va='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Coefficient statistics\n",
    "    zero_coef_features = coef_df[coef_df['Abs_Average'] < 1e-6]['Feature'].tolist()\n",
    "    non_zero_features = len(feature_names) - len(zero_coef_features)\n",
    "    \n",
    "    print(f\"Non-zero coefficients: {non_zero_features}/{len(feature_names)}\")\n",
    "    if zero_coef_features:\n",
    "        print(f\"Features with zero coefficients: {zero_coef_features}\")\n",
    "    \n",
    "    print(f\"\\nTop 10 Features by Absolute Coefficient Value:\")\n",
    "    top_coef = coef_df.tail(10)[['Feature', 'Average']].copy()\n",
    "    print(top_coef.to_string(index=False))\n",
    "    \n",
    "    return results_1d, results_20d\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('DATA.csv')\n",
    "\n",
    "\n",
    "# Version 2: Interest Rate continuous variable\n",
    "continuous_features_ir = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct',  'J', \n",
    "                          'mfi', 'MACD', 'MACD_diff',  'BB_rel_pos', 'Vol_Change', 'Interest_Rate']\n",
    "binary_features_base = ['MA5_GT_MA20']\n",
    "\n",
    "results_ir = run_svm_model(df, continuous_features_ir, binary_features_base, \n",
    "                          \"with Interest Rate\", \"with Interest Rate\")\n",
    "\n",
    "# Version 3: btc\n",
    "continuous_features_btc = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct',  'J', \n",
    "                          'mfi', 'MACD', 'MACD_diff',  'BB_rel_pos', 'Vol_Change', 'Bitcoin_Close']\n",
    "binary_features_base = ['MA5_GT_MA20']\n",
    "\n",
    "results_btc = run_svm_model(df, continuous_features_btc, binary_features_base, \n",
    "                          \"with BTC\", \"with BTC\")\n",
    "\n",
    "# Version 4: gold\n",
    "continuous_features_gold = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct',  'J', \n",
    "                          'mfi', 'MACD', 'MACD_diff',  'BB_rel_pos', 'Vol_Change', 'Gold_Close']\n",
    "binary_features_base = ['MA5_GT_MA20']\n",
    "\n",
    "results_gold = run_svm_model(df, continuous_features_gold, binary_features_base, \n",
    "                          \"with Gold\", \"with Gold\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6091605-2212-43de-a75f-6c91a33b410f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
