{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37601a25-2147-4c7a-b777-03dd6aa63480",
   "metadata": {},
   "source": [
    "# base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70be08be-807b-423d-8cde-3b5933a61a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "def run_xgboost_model(df, continuous_features, binary_features, model_name, title_suffix):\n",
    "    \"\"\"\n",
    "    Universal XGBoost model training and evaluation function with early stopping and SHAP analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    # Data splitting by company in chronological order\n",
    "    train_data_list = []\n",
    "    val_data_list = []\n",
    "    test_data_list = []\n",
    "\n",
    "    for company in df['Company'].unique():\n",
    "        company_data = df[df['Company'] == company].copy()\n",
    "        company_data = company_data.sort_values('Date')\n",
    "        \n",
    "        n_company = len(company_data)\n",
    "        train_size = int(0.7 * n_company)\n",
    "        val_size = int(0.15 * n_company)\n",
    "        \n",
    "        train_data_list.append(company_data.iloc[:train_size])\n",
    "        val_data_list.append(company_data.iloc[train_size:train_size+val_size])\n",
    "        test_data_list.append(company_data.iloc[train_size+val_size:])\n",
    "\n",
    "    train_data = pd.concat(train_data_list, ignore_index=True)\n",
    "    val_data = pd.concat(val_data_list, ignore_index=True)\n",
    "    test_data = pd.concat(test_data_list, ignore_index=True)\n",
    "\n",
    "    print(f\"Training set size: {len(train_data)}\")\n",
    "    print(f\"Validation set size: {len(val_data)}\")\n",
    "    print(f\"Test set size: {len(test_data)}\")\n",
    "    \n",
    "    # Data preprocessing\n",
    "    def preprocess_data(train_df, val_df, test_df, target_col, continuous_features, binary_features):\n",
    "        all_features = continuous_features + binary_features\n",
    "        \n",
    "        train_df = train_df.dropna(subset=all_features + [target_col])\n",
    "        val_df = val_df.dropna(subset=all_features + [target_col])\n",
    "        test_df = test_df.dropna(subset=all_features + [target_col])\n",
    "        \n",
    "        X_train_continuous = train_df[continuous_features]\n",
    "        X_val_continuous = val_df[continuous_features]\n",
    "        X_test_continuous = test_df[continuous_features]\n",
    "        \n",
    "        X_train_binary = train_df[binary_features]\n",
    "        X_val_binary = val_df[binary_features]\n",
    "        X_test_binary = test_df[binary_features]\n",
    "        \n",
    "        y_train = train_df[target_col]\n",
    "        y_val = val_df[target_col]\n",
    "        y_test = test_df[target_col]\n",
    "        \n",
    "        # Standardize only continuous features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_continuous_scaled = scaler.fit_transform(X_train_continuous)\n",
    "        X_val_continuous_scaled = scaler.transform(X_val_continuous)\n",
    "        X_test_continuous_scaled = scaler.transform(X_test_continuous)\n",
    "        \n",
    "        # Combine scaled continuous features with unscaled binary features\n",
    "        X_train_scaled = np.hstack([X_train_continuous_scaled, X_train_binary.values])\n",
    "        X_val_scaled = np.hstack([X_val_continuous_scaled, X_val_binary.values])\n",
    "        X_test_scaled = np.hstack([X_test_continuous_scaled, X_test_binary.values])\n",
    "        \n",
    "        return X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, scaler\n",
    "\n",
    "    def evaluate_model(y_true, y_pred, y_prob, model_name):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        auc = roc_auc_score(y_true, y_prob)\n",
    "        precision_per_class = precision_score(y_true, y_pred, average=None)\n",
    "        recall_per_class = recall_score(y_true, y_pred, average=None)\n",
    "        f1_per_class = f1_score(y_true, y_pred, average=None)\n",
    "        \n",
    "        # Confusion matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                    yticklabels=['Actual 0', 'Actual 1'])\n",
    "        plt.title(f'{model_name} XGBoost {title_suffix} - Confusion Matrix')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.show()\n",
    "        \n",
    "        # Performance metrics table\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.axis('tight')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        table_data = [\n",
    "            ['Metric', 'Value'],\n",
    "            ['Macro F1 Score', f'{f1_macro:.4f}'],\n",
    "            ['Overall Accuracy', f'{accuracy:.4f}'],\n",
    "            ['AUC', f'{auc:.4f}'],\n",
    "            ['', ''],\n",
    "            ['Class 1 Precision', f'{precision_per_class[1]:.4f}'],\n",
    "            ['Class 1 Recall', f'{recall_per_class[1]:.4f}'],\n",
    "            ['Class 1 F1', f'{f1_per_class[1]:.4f}'],\n",
    "            ['', ''],\n",
    "            ['Class 0 Precision', f'{precision_per_class[0]:.4f}'],\n",
    "            ['Class 0 Recall', f'{recall_per_class[0]:.4f}'],\n",
    "            ['Class 0 F1', f'{f1_per_class[0]:.4f}']\n",
    "        ]\n",
    "        \n",
    "        table = plt.table(cellText=table_data[1:], colLabels=table_data[0],\n",
    "                         cellLoc='center', loc='center', colWidths=[0.4, 0.3])\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(12)\n",
    "        table.scale(1.5, 2)\n",
    "        \n",
    "        for i in range(len(table_data)):\n",
    "            for j in range(len(table_data[0])):\n",
    "                cell = table[(i, j)]\n",
    "                if i == 0:\n",
    "                    cell.set_facecolor('#4CAF50')\n",
    "                    cell.set_text_props(weight='bold', color='white')\n",
    "                elif len(table_data[i]) > 0 and table_data[i][0] == '':\n",
    "                    cell.set_facecolor('#ffffff')\n",
    "                    cell.set_text_props(color='white')\n",
    "                else:\n",
    "                    cell.set_facecolor('#f0f0f0')\n",
    "        \n",
    "        plt.title(f'{model_name} XGBoost {title_suffix} - Performance Metrics', fontsize=16, fontweight='bold', pad=20)\n",
    "        plt.show()\n",
    "        \n",
    "        return {'confusion_matrix': cm, 'f1_macro': f1_macro, 'accuracy': accuracy, 'auc': auc,\n",
    "                'class_0_precision': precision_per_class[0], 'class_0_recall': recall_per_class[0], 'class_0_f1': f1_per_class[0],\n",
    "                'class_1_precision': precision_per_class[1], 'class_1_recall': recall_per_class[1], 'class_1_f1': f1_per_class[1]}\n",
    "\n",
    "    def generate_shap_analysis(model, X_test, feature_names, model_name):\n",
    "        \"\"\"\n",
    "        Generate enhanced SHAP analysis with summary plot, waterfall plot, and feature importance ranking\n",
    "        \"\"\"\n",
    "        print(f\"\\nGenerating SHAP analysis for {model_name}...\")\n",
    "        \n",
    "        # Create SHAP explainer\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "        \n",
    "        # SHAP Summary Plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.summary_plot(shap_values, X_test, feature_names=feature_names, show=False)\n",
    "        plt.title(f'SHAP Summary Plot - {model_name}', fontsize=14, fontweight='bold', pad=20)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # SHAP Waterfall Plot for first test sample\n",
    "        # Create explanation object for waterfall plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Convert to pandas DataFrame for better compatibility\n",
    "        X_test_df = pd.DataFrame(X_test, columns=feature_names)\n",
    "        \n",
    "        # Create Explanation object for waterfall plot\n",
    "        explanation = shap.Explanation(\n",
    "            values=shap_values[0], \n",
    "            base_values=explainer.expected_value, \n",
    "            data=X_test[0],\n",
    "            feature_names=feature_names\n",
    "        )\n",
    "        \n",
    "        shap.waterfall_plot(explanation, show=False)\n",
    "        plt.title(f'SHAP Waterfall Plot - First Test Sample - {model_name}', \n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate mean SHAP values (with direction) and mean absolute SHAP values (for sorting)\n",
    "        mean_shap_values = np.mean(shap_values, axis=0)  \n",
    "        mean_abs_shap_values = np.mean(np.abs(shap_values), axis=0)  \n",
    "        \n",
    "        # Create DataFrame with both metrics\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Mean_SHAP': mean_shap_values,  \n",
    "            'Mean_Abs_SHAP': mean_abs_shap_values  \n",
    "        }).sort_values('Mean_Abs_SHAP', ascending=False)  \n",
    "        \n",
    "        print(f\"\\nFeature Importance Ranking for {model_name} (sorted by absolute value, preserving direction):\")\n",
    "        print(\"=\" * 75)\n",
    "        print(f\"{'Rank':<4} {'Feature':<25} {'Mean SHAP':<12} {'|Mean SHAP|':<12} {'Direction':<12}\")\n",
    "        print(\"-\" * 75)\n",
    "        \n",
    "        for i, (_, row) in enumerate(importance_df.iterrows(), 1):\n",
    "            direction = \"Positive\" if row['Mean_SHAP'] > 0 else \"Negative\"\n",
    "            direction_symbol = \"↑\" if row['Mean_SHAP'] > 0 else \"↓\"\n",
    "            \n",
    "            print(f\"{i:2d}.  {row['Feature']:<25} {row['Mean_SHAP']:>+10.6f} {row['Mean_Abs_SHAP']:>10.6f}   {direction_symbol} {direction}\")\n",
    "        \n",
    "        # Create visualization chart showing directional importance\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        # Get sorted data\n",
    "        sorted_features = importance_df['Feature'].values\n",
    "        sorted_mean_shap = importance_df['Mean_SHAP'].values\n",
    "        \n",
    "        # Create colors: green for positive, red for negative\n",
    "        colors = ['green' if x > 0 else 'red' for x in sorted_mean_shap]\n",
    "        \n",
    "        # Create horizontal bar chart\n",
    "        y_pos = np.arange(len(sorted_features))\n",
    "        bars = plt.barh(y_pos, sorted_mean_shap, color=colors, alpha=0.7)\n",
    "        \n",
    "        # Set labels and title\n",
    "        plt.yticks(y_pos, sorted_features)\n",
    "        plt.xlabel('Mean SHAP Value (with direction)')\n",
    "        plt.title(f'Feature Importance with Direction - {model_name}\\n(Sorted by absolute value, preserving positive/negative direction)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Add zero line\n",
    "        plt.axvline(x=0, color='black', linestyle='-', alpha=0.8, linewidth=1)\n",
    "        \n",
    "        # Add legend\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [Patch(facecolor='green', alpha=0.7, label='Positive Impact (promotes upward movement)'),\n",
    "                          Patch(facecolor='red', alpha=0.7, label='Negative Impact (promotes downward movement)')]\n",
    "        plt.legend(handles=legend_elements, loc='lower right')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, (bar, value) in enumerate(zip(bars, sorted_mean_shap)):\n",
    "            if value > 0:\n",
    "                plt.text(value + 0.0001, bar.get_y() + bar.get_height()/2, \n",
    "                        f'{value:.4f}', ha='left', va='center', fontsize=9)\n",
    "            else:\n",
    "                plt.text(value - 0.0001, bar.get_y() + bar.get_height()/2, \n",
    "                        f'{value:.4f}', ha='right', va='center', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return shap_values\n",
    "\n",
    "    # Model training\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"XGBoost {model_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # XGBoost hyperparameter grid for optimization\n",
    "    param_grid = {\n",
    "        'max_depth': [4,5,6],\n",
    "        'learning_rate': [ 0.1, 0.15,0.2],\n",
    "        'n_estimators': [200,300, 500],\n",
    "        'subsample': [0.8, 0.9],\n",
    "        'colsample_bytree': [0.8, 0.9],\n",
    "        'reg_alpha': [0,0.01, 0.1],\n",
    "        'reg_lambda': [0.5,1, 2]\n",
    "    }\n",
    "    \n",
    "    # Base XGBoost parameters\n",
    "    base_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'min_child_weight': 1,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    feature_names = continuous_features + binary_features\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    # 1D Model\n",
    "    X_train_1d, y_train_1d, X_val_1d, y_val_1d, X_test_1d, y_test_1d, scaler_1d = preprocess_data(\n",
    "        train_data, val_data, test_data, '1D_Up', continuous_features, binary_features)\n",
    "    \n",
    "    print(\"Hyperparameter tuning for 1D XGBoost model...\")\n",
    "    \n",
    "    # Grid search with time series cross validation\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(**base_params)\n",
    "    \n",
    "    grid_search_1d = GridSearchCV(\n",
    "        xgb_model,\n",
    "        param_grid,\n",
    "        cv=tscv,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search_1d.fit(X_train_1d, y_train_1d)\n",
    "    best_params_1d = grid_search_1d.best_params_\n",
    "    \n",
    "    print(f\"Best parameters for 1D model: {best_params_1d}\")\n",
    "    print(f\"Best cross-validation F1 score: {grid_search_1d.best_score_:.4f}\")\n",
    "    \n",
    "    # Train final model with best parameters and early stopping\n",
    "    final_params_1d = {**base_params, **best_params_1d}\n",
    "    model_1d = xgb.XGBClassifier(**final_params_1d, early_stopping_rounds=50)\n",
    "    \n",
    "    model_1d.fit(\n",
    "        X_train_1d, y_train_1d,\n",
    "        eval_set=[(X_val_1d, y_val_1d)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    print(f\"1D Model stopped at iteration: {model_1d.best_iteration}\")\n",
    "    print(f\"1D Model best validation AUC: {model_1d.best_score:.4f}\")\n",
    "    \n",
    "    y_pred_1d = model_1d.predict(X_test_1d)\n",
    "    y_prob_1d = model_1d.predict_proba(X_test_1d)[:, 1]\n",
    "    \n",
    "    results_1d = evaluate_model(y_test_1d, y_pred_1d, y_prob_1d, \"1D_Up Prediction\")\n",
    "    \n",
    "    # Generate SHAP analysis for 1D model\n",
    "    shap_values_1d = generate_shap_analysis(model_1d, X_test_1d, feature_names, \"1D_Up Prediction\")\n",
    "    \n",
    "    # 20D Model\n",
    "    X_train_20d, y_train_20d, X_val_20d, y_val_20d, X_test_20d, y_test_20d, scaler_20d = preprocess_data(\n",
    "        train_data, val_data, test_data, '20D_Up', continuous_features, binary_features)\n",
    "    \n",
    "    print(\"\\nHyperparameter tuning for 20D XGBoost model...\")\n",
    "    \n",
    "    grid_search_20d = GridSearchCV(\n",
    "        xgb.XGBClassifier(**base_params),\n",
    "        param_grid,\n",
    "        cv=tscv,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search_20d.fit(X_train_20d, y_train_20d)\n",
    "    best_params_20d = grid_search_20d.best_params_\n",
    "    \n",
    "    print(f\"Best parameters for 20D model: {best_params_20d}\")\n",
    "    print(f\"Best cross-validation F1 score: {grid_search_20d.best_score_:.4f}\")\n",
    "    \n",
    "    # Train final model with best parameters and early stopping\n",
    "    final_params_20d = {**base_params, **best_params_20d}\n",
    "    model_20d = xgb.XGBClassifier(**final_params_20d, early_stopping_rounds=50)\n",
    "    \n",
    "    model_20d.fit(\n",
    "        X_train_20d, y_train_20d,\n",
    "        eval_set=[(X_val_20d, y_val_20d)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    print(f\"20D Model stopped at iteration: {model_20d.best_iteration}\")\n",
    "    print(f\"20D Model best validation AUC: {model_20d.best_score:.4f}\")\n",
    "    \n",
    "    y_pred_20d = model_20d.predict(X_test_20d)\n",
    "    y_prob_20d = model_20d.predict_proba(X_test_20d)[:, 1]\n",
    "    \n",
    "    results_20d = evaluate_model(y_test_20d, y_pred_20d, y_prob_20d, \"20D_Up Prediction\")\n",
    "    \n",
    "    # Generate SHAP analysis for 20D model\n",
    "    shap_values_20d = generate_shap_analysis(model_20d, X_test_20d, feature_names, \"20D_Up Prediction\")\n",
    "    \n",
    "    # Model performance summary\n",
    "    print(f\"\\nModel Performance Summary:\")\n",
    "    print(f\"1D Model - AUC: {results_1d['auc']:.4f}, F1: {results_1d['f1_macro']:.4f}\")\n",
    "    print(f\"20D Model - AUC: {results_20d['auc']:.4f}, F1: {results_20d['f1_macro']:.4f}\")\n",
    "    print(f\"1D Best Params: {best_params_1d}\")\n",
    "    print(f\"20D Best Params: {best_params_20d}\")\n",
    "    \n",
    "    return results_1d, results_20d, model_1d, model_20d\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('DATA.csv')\n",
    "\n",
    "# Version 1: Baseline Model\n",
    "continuous_features_base = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct', 'J', \n",
    "                           'mfi', 'MACD', 'MACD_diff',  'BB_rel_pos', 'Vol_Change']\n",
    "binary_features_base = ['MA5_GT_MA20']\n",
    "\n",
    "print(\"\\nVERSION 1: Baseline Model (Technical Indicators Only)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "results_baseline = run_xgboost_model(df, continuous_features_base, binary_features_base, \n",
    "                                    \"Baseline\", \"Baseline\")\n",
    "\n",
    "# Version 2: Interest Rate Continuous\n",
    "continuous_features_ir = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct', 'J', \n",
    "                          'mfi', 'MACD', 'MACD_diff',  'BB_rel_pos', 'Vol_Change', 'Interest_Rate']\n",
    "\n",
    "print(\"\\nVERSION 2: Interest Rate Continuous\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "results_ir = run_xgboost_model(df, continuous_features_ir, binary_features_base, \n",
    "                              \"with Interest Rate\", \"with Interest Rate\")\n",
    "\n",
    "# Version 3: BTC\n",
    "\n",
    "continuous_features_btc = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct', 'J', \n",
    "                          'mfi', 'MACD', 'MACD_diff',  'BB_rel_pos', 'Vol_Change', 'Bitcoin_Close']\n",
    "\n",
    "print(\"\\nVERSION 3: BTC\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "results_btc = run_xgboost_model(df, continuous_features_btc, binary_features_base,\n",
    "                                     \"with BTC\", \"with BTC\")\n",
    "\n",
    "# Version 4: Gold\n",
    "\n",
    "continuous_features_gold = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct', 'J', \n",
    "                          'mfi', 'MACD', 'MACD_diff',  'BB_rel_pos', 'Vol_Change', 'Gold_Close']\n",
    "\n",
    "print(\"\\nVERSION 4: Gold\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "results__gold = run_xgboost_model(df, continuous_features_gold, binary_features_base,\n",
    "                                     \"with Gold\", \"with Gold\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe733f55-0dbe-4749-be3e-0b2bb0d880c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd568ee9-a1df-4be2-a3fc-d3734e5fa5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbea6b7b-1903-4f26-a13d-e8d570ca0980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
