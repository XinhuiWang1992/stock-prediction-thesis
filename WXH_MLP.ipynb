{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab79f89-764b-4af1-8246-2aaffb6ec040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62151e47-1e8f-4f51-9a8f-8a97a92621ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set all random seeds for reproducibility\n",
    "def set_random_seeds(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set random seeds\n",
    "set_random_seeds(42)\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Set device and optimize for CPU\n",
    "device = torch.device('cpu')\n",
    "torch.set_num_threads(4)\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"CPU threads: {torch.get_num_threads()}\")\n",
    "\n",
    "class MLPDataset(Dataset):\n",
    "    def __init__(self, X, y, seed=42):\n",
    "        torch.manual_seed(seed)\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.LongTensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, dropout_rate=0.1):\n",
    "        super(MLPModel, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        layers.append(nn.Linear(prev_size, 2))  # Binary classification\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=15, min_delta=0.001, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(model)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            \n",
    "        if self.counter >= self.patience:\n",
    "            if self.restore_best_weights:\n",
    "                model.load_state_dict(self.best_weights)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def save_checkpoint(self, model):\n",
    "        self.best_weights = model.state_dict().copy()\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=500, lr=0.01, patience=15, seed=42):\n",
    "    \"\"\"\n",
    "    Train model with early stopping monitored on separate validation set\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    early_stopping = EarlyStopping(patience=patience)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation phase - early stopping monitored here\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            print(f'    Epoch {epoch}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "        \n",
    "        # Early stopping based on validation loss\n",
    "        if early_stopping(val_loss, model):\n",
    "            if epoch > 10:\n",
    "                print(f'    Early stopping at epoch {epoch}')\n",
    "                break\n",
    "    \n",
    "    return train_losses, val_losses, epoch + 1\n",
    "\n",
    "def predict_model(model, data_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, _ in data_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            probabilities.extend(probs[:, 1].cpu().numpy())\n",
    "    \n",
    "    return np.array(predictions), np.array(probabilities)\n",
    "\n",
    "def generate_shap_analysis(model, X_test, feature_names, model_name):\n",
    "    \"\"\"\n",
    "    Generate SHAP analysis for model interpretability\n",
    "    \"\"\"\n",
    "    print(f\"\\nGenerating SHAP analysis for {model_name}...\")\n",
    "    \n",
    "    def model_predict_proba(X):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.FloatTensor(X).to(device)\n",
    "            outputs = model(X_tensor)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            return probs.cpu().numpy()\n",
    "    \n",
    "    def model_predict_class1(X):\n",
    "        return model_predict_proba(X)[:, 1]\n",
    "    \n",
    "    background_size = min(100, len(X_test))\n",
    "    background_indices = np.linspace(0, len(X_test)-1, background_size, dtype=int)\n",
    "    background_data = X_test[background_indices]\n",
    "    \n",
    "    print(f\"Using {background_size} background samples for SHAP explainer...\")\n",
    "    explainer = shap.KernelExplainer(model_predict_class1, background_data)\n",
    "    \n",
    "    print(f\"Computing SHAP values for test set ({len(X_test)} samples)...\")\n",
    "    \n",
    "    batch_size = 50\n",
    "    all_shap_values = []\n",
    "    \n",
    "    for i in range(0, len(X_test), batch_size):\n",
    "        end_idx = min(i + batch_size, len(X_test))\n",
    "        batch_data = X_test[i:end_idx]\n",
    "        print(f\"Processing batch {i//batch_size + 1}/{(len(X_test)-1)//batch_size + 1}\")\n",
    "        \n",
    "        batch_shap_values = explainer.shap_values(batch_data)\n",
    "        all_shap_values.append(batch_shap_values)\n",
    "    \n",
    "    shap_values = np.vstack(all_shap_values)\n",
    "    feature_names_array = np.array(feature_names)\n",
    "    \n",
    "    # SHAP Summary Plot\n",
    "    try:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.summary_plot(shap_values, X_test, feature_names=feature_names_array, show=False)\n",
    "        plt.title(f'SHAP Summary Plot - {model_name}', fontsize=14, fontweight='bold', pad=20)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Summary plot failed: {e}\")\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        feature_importance = np.abs(shap_values).mean(0)\n",
    "        sorted_idx = np.argsort(feature_importance)\n",
    "        \n",
    "        plt.barh(range(len(feature_importance)), feature_importance[sorted_idx])\n",
    "        plt.yticks(range(len(feature_importance)), feature_names_array[sorted_idx])\n",
    "        plt.xlabel('Mean |SHAP value| (Feature Importance)')\n",
    "        plt.title(f'Feature Importance - {model_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Feature importance ranking\n",
    "    mean_shap_values = np.mean(shap_values, axis=0)\n",
    "    mean_abs_shap_values = np.mean(np.abs(shap_values), axis=0)\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names_array,\n",
    "        'Mean_SHAP': mean_shap_values,\n",
    "        'Mean_Abs_SHAP': mean_abs_shap_values\n",
    "    }).sort_values('Mean_Abs_SHAP', ascending=False)\n",
    "    \n",
    "    print(f\"\\nFeature Importance Ranking for {model_name}:\")\n",
    "    print(\"=\" * 75)\n",
    "    print(f\"{'Rank':<4} {'Feature':<25} {'Mean SHAP':<12} {'|Mean SHAP|':<12} {'Direction':<12}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    for i, (_, row) in enumerate(importance_df.iterrows(), 1):\n",
    "        direction = \"Positive\" if row['Mean_SHAP'] > 0 else \"Negative\"\n",
    "        direction_symbol = \"↑\" if row['Mean_SHAP'] > 0 else \"↓\"\n",
    "        \n",
    "        print(f\"{i:2d}.  {row['Feature']:<25} {row['Mean_SHAP']:>+10.6f} {row['Mean_Abs_SHAP']:>10.6f}   {direction_symbol} {direction}\")\n",
    "    \n",
    "    return shap_values\n",
    "\n",
    "def run_mlp_model(df, continuous_features, binary_features, model_name, title_suffix):\n",
    "    \"\"\"\n",
    "    PyTorch MLP model with 5-fold TimeSeriesSplit cross-validation for hyperparameter selection\n",
    "    Early stopping monitored on separate validation set\n",
    "    \"\"\"\n",
    "    \n",
    "    # Data splitting by company in chronological order\n",
    "    train_data_list = []\n",
    "    val_data_list = []\n",
    "    test_data_list = []\n",
    "\n",
    "    for company in df['Company'].unique():\n",
    "        company_data = df[df['Company'] == company].copy()\n",
    "        company_data = company_data.sort_values('Date')\n",
    "        \n",
    "        n_company = len(company_data)\n",
    "        train_size = int(0.7 * n_company)\n",
    "        val_size = int(0.15 * n_company)\n",
    "        \n",
    "        train_data_list.append(company_data.iloc[:train_size])\n",
    "        val_data_list.append(company_data.iloc[train_size:train_size+val_size])\n",
    "        test_data_list.append(company_data.iloc[train_size+val_size:])\n",
    "\n",
    "    train_data = pd.concat(train_data_list, ignore_index=True)\n",
    "    val_data = pd.concat(val_data_list, ignore_index=True)\n",
    "    test_data = pd.concat(test_data_list, ignore_index=True)\n",
    "\n",
    "    print(f\"Training set size: {len(train_data)}\")\n",
    "    print(f\"Validation set size: {len(val_data)}\")\n",
    "    print(f\"Test set size: {len(test_data)}\")\n",
    "    \n",
    "    def preprocess_data(train_df, val_df, test_df, target_col, continuous_features, binary_features):\n",
    "        all_features = continuous_features + binary_features\n",
    "        \n",
    "        train_df = train_df.dropna(subset=all_features + [target_col])\n",
    "        val_df = val_df.dropna(subset=all_features + [target_col])\n",
    "        test_df = test_df.dropna(subset=all_features + [target_col])\n",
    "        \n",
    "        X_train_continuous = train_df[continuous_features]\n",
    "        X_val_continuous = val_df[continuous_features]\n",
    "        X_test_continuous = test_df[continuous_features]\n",
    "        \n",
    "        X_train_binary = train_df[binary_features]\n",
    "        X_val_binary = val_df[binary_features]\n",
    "        X_test_binary = test_df[binary_features]\n",
    "        \n",
    "        y_train = train_df[target_col]\n",
    "        y_val = val_df[target_col]\n",
    "        y_test = test_df[target_col]\n",
    "        \n",
    "        # Standardize continuous features\n",
    "        scaler_continuous = StandardScaler()\n",
    "        X_train_continuous_scaled = scaler_continuous.fit_transform(X_train_continuous)\n",
    "        X_val_continuous_scaled = scaler_continuous.transform(X_val_continuous)\n",
    "        X_test_continuous_scaled = scaler_continuous.transform(X_test_continuous)\n",
    "        \n",
    "        # Standardize binary features\n",
    "        if len(binary_features) > 0:\n",
    "            scaler_binary = StandardScaler()\n",
    "            X_train_binary_scaled = scaler_binary.fit_transform(X_train_binary)\n",
    "            X_val_binary_scaled = scaler_binary.transform(X_val_binary)\n",
    "            X_test_binary_scaled = scaler_binary.transform(X_test_binary)\n",
    "            \n",
    "            X_train_scaled = np.hstack([X_train_continuous_scaled, X_train_binary_scaled])\n",
    "            X_val_scaled = np.hstack([X_val_continuous_scaled, X_val_binary_scaled])\n",
    "            X_test_scaled = np.hstack([X_test_continuous_scaled, X_test_binary_scaled])\n",
    "        else:\n",
    "            X_train_scaled = X_train_continuous_scaled\n",
    "            X_val_scaled = X_val_continuous_scaled\n",
    "            X_test_scaled = X_test_continuous_scaled\n",
    "        \n",
    "        return X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test\n",
    "\n",
    "    def evaluate_model(y_true, y_pred, y_prob, model_name):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        auc = roc_auc_score(y_true, y_prob)\n",
    "        precision_per_class = precision_score(y_true, y_pred, average=None)\n",
    "        recall_per_class = recall_score(y_true, y_pred, average=None)\n",
    "        f1_per_class = f1_score(y_true, y_pred, average=None)\n",
    "        \n",
    "        # Confusion matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                    yticklabels=['Actual 0', 'Actual 1'])\n",
    "        plt.title(f'{model_name} MLP {title_suffix} - Confusion Matrix')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.show()\n",
    "        \n",
    "        # Performance metrics table\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.axis('tight')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        table_data = [\n",
    "            ['Metric', 'Value'],\n",
    "            ['Macro F1 Score', f'{f1_macro:.4f}'],\n",
    "            ['Overall Accuracy', f'{accuracy:.4f}'],\n",
    "            ['AUC', f'{auc:.4f}'],\n",
    "            ['', ''],\n",
    "            ['Class 1 Precision', f'{precision_per_class[1]:.4f}'],\n",
    "            ['Class 1 Recall', f'{recall_per_class[1]:.4f}'],\n",
    "            ['Class 1 F1', f'{f1_per_class[1]:.4f}'],\n",
    "            ['', ''],\n",
    "            ['Class 0 Precision', f'{precision_per_class[0]:.4f}'],\n",
    "            ['Class 0 Recall', f'{recall_per_class[0]:.4f}'],\n",
    "            ['Class 0 F1', f'{f1_per_class[0]:.4f}']\n",
    "        ]\n",
    "        \n",
    "        table = plt.table(cellText=table_data[1:], colLabels=table_data[0],\n",
    "                         cellLoc='center', loc='center', colWidths=[0.4, 0.3])\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(12)\n",
    "        table.scale(1.5, 2)\n",
    "        \n",
    "        for i in range(len(table_data)):\n",
    "            for j in range(len(table_data[0])):\n",
    "                cell = table[(i, j)]\n",
    "                if i == 0:\n",
    "                    cell.set_facecolor('#4CAF50')\n",
    "                    cell.set_text_props(weight='bold', color='white')\n",
    "                elif len(table_data[i]) > 0 and table_data[i][0] == '':\n",
    "                    cell.set_facecolor('#ffffff')\n",
    "                    cell.set_text_props(color='white')\n",
    "                else:\n",
    "                    cell.set_facecolor('#f0f0f0')\n",
    "        \n",
    "        plt.title(f'{model_name} MLP {title_suffix} - Performance Metrics', fontsize=16, fontweight='bold', pad=20)\n",
    "        plt.show()\n",
    "        \n",
    "        return {'confusion_matrix': cm, 'f1_macro': f1_macro, 'accuracy': accuracy, 'auc': auc,\n",
    "                'class_0_precision': precision_per_class[0], 'class_0_recall': recall_per_class[0], 'class_0_f1': f1_per_class[0],\n",
    "                'class_1_precision': precision_per_class[1], 'class_1_recall': recall_per_class[1], 'class_1_f1': f1_per_class[1]}\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"PyTorch MLP {model_name} with 5-Fold TimeSeriesSplit CV\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    feature_names = continuous_features + binary_features\n",
    "    \n",
    "    # Hyperparameter configurations\n",
    "    configs = [\n",
    "        # Single layer networks\n",
    "        {'hidden_sizes': [32], 'lr': 0.001, 'dropout': 0.1},\n",
    "\n",
    "        {'hidden_sizes': [64], 'lr': 0.001, 'dropout': 0.1},\n",
    "         {'hidden_sizes': [128], 'lr': 0.001, 'dropout': 0.1},\n",
    "        \n",
    "        # Two layer networks\n",
    "        {'hidden_sizes': [64, 32], 'lr': 0.001, 'dropout': 0.2},\n",
    "        {'hidden_sizes': [128, 64], 'lr': 0.001, 'dropout': 0.2},\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    # Initialize 5-fold TimeSeriesSplit\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    # 1D Model with 5-fold CV hyperparameter selection\n",
    "    X_train_1d, y_train_1d, X_val_1d, y_val_1d, X_test_1d, y_test_1d = preprocess_data(\n",
    "        train_data, val_data, test_data, '1D_Up', continuous_features, binary_features)\n",
    "    \n",
    "    print(\"Training 1D MLP model with 5-fold TimeSeriesSplit CV...\")\n",
    "    \n",
    "    best_cv_score_1d = float('inf')\n",
    "    best_config_1d = None\n",
    "    best_model_1d = None\n",
    "    \n",
    "    # 5-fold cross-validation for hyperparameter selection\n",
    "    for i, config in enumerate(configs):\n",
    "        print(f\"\\nConfiguration {i+1}/{len(configs)}: {config}\")\n",
    "        \n",
    "        cv_scores = []\n",
    "        \n",
    "        # 5-fold TimeSeriesSplit cross-validation\n",
    "        for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train_1d)):\n",
    "            print(f\"  Fold {fold + 1}/5\")\n",
    "            \n",
    "            # Split data for this fold\n",
    "            X_train_fold = X_train_1d[train_idx]\n",
    "            X_val_fold = X_train_1d[val_idx]  # CV validation (different from early stopping validation)\n",
    "            y_train_fold = y_train_1d.iloc[train_idx]\n",
    "            y_val_fold = y_train_1d.iloc[val_idx]\n",
    "            \n",
    "            # Create datasets\n",
    "            train_dataset = MLPDataset(X_train_fold, y_train_fold.values, seed=42)\n",
    "            val_dataset = MLPDataset(X_val_fold, y_val_fold.values, seed=42)\n",
    "            \n",
    "            generator = torch.Generator()\n",
    "            generator.manual_seed(42 + fold)\n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, generator=generator)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "            \n",
    "            # Create model\n",
    "            torch.manual_seed(42 + i * 10 + fold)\n",
    "            model = MLPModel(X_train_1d.shape[1], config['hidden_sizes'], config['dropout']).to(device)\n",
    "            \n",
    "            # Train model (early stopping monitored on fold validation set)\n",
    "            train_losses, val_losses, epochs_trained = train_model(\n",
    "                model, train_loader, val_loader, lr=config['lr'], patience=15, seed=42 + i * 10 + fold\n",
    "            )\n",
    "            \n",
    "            # Record fold validation loss\n",
    "            fold_val_loss = val_losses[-1]\n",
    "            cv_scores.append(fold_val_loss)\n",
    "            print(f\"    Fold {fold + 1} validation loss: {fold_val_loss:.4f}\")\n",
    "        \n",
    "        # Calculate average CV score\n",
    "        mean_cv_score = np.mean(cv_scores)\n",
    "        std_cv_score = np.std(cv_scores)\n",
    "        print(f\"  Average CV Score: {mean_cv_score:.4f} ± {std_cv_score:.4f}\")\n",
    "        \n",
    "        # If this configuration is better, retrain on full training set\n",
    "        if mean_cv_score < best_cv_score_1d:\n",
    "            best_cv_score_1d = mean_cv_score\n",
    "            best_config_1d = config\n",
    "            \n",
    "            print(f\"  New best config! Retraining on full training set...\")\n",
    "            \n",
    "            # Retrain best model on full training set (early stopping on separate validation set)\n",
    "            train_dataset_full = MLPDataset(X_train_1d, y_train_1d.values, seed=42)\n",
    "            val_dataset_full = MLPDataset(X_val_1d, y_val_1d.values, seed=42)  # Separate validation set for early stopping\n",
    "            \n",
    "            generator_full = torch.Generator()\n",
    "            generator_full.manual_seed(42)\n",
    "            \n",
    "            train_loader_full = DataLoader(train_dataset_full, batch_size=32, shuffle=True, generator=generator_full)\n",
    "            val_loader_full = DataLoader(val_dataset_full, batch_size=32, shuffle=False)\n",
    "            \n",
    "            torch.manual_seed(42 + i)\n",
    "            best_model_1d = MLPModel(X_train_1d.shape[1], config['hidden_sizes'], config['dropout']).to(device)\n",
    "            \n",
    "            # Train with early stopping on separate validation set\n",
    "            train_losses, val_losses, epochs_trained = train_model(\n",
    "                best_model_1d, train_loader_full, val_loader_full, lr=config['lr'], patience=15, seed=42 + i\n",
    "            )\n",
    "    \n",
    "    print(f\"\\nBest configuration for 1D model: {best_config_1d}\")\n",
    "    print(f\"Best CV score: {best_cv_score_1d:.4f}\")\n",
    "    \n",
    "    # Evaluate 1D model on test set\n",
    "    test_dataset_1d = MLPDataset(X_test_1d, y_test_1d.values)\n",
    "    test_loader_1d = DataLoader(test_dataset_1d, batch_size=32, shuffle=False)\n",
    "    \n",
    "    y_pred_1d, y_prob_1d = predict_model(best_model_1d, test_loader_1d)\n",
    "    results_1d = evaluate_model(y_test_1d, y_pred_1d, y_prob_1d, \"1D_Up Prediction\")\n",
    "    \n",
    "    # Generate SHAP analysis for 1D model\n",
    "    shap_values_1d = generate_shap_analysis(best_model_1d, X_test_1d, feature_names, \"1D_Up Prediction\")\n",
    "    \n",
    "    # 20D Model with 5-fold CV hyperparameter selection\n",
    "    X_train_20d, y_train_20d, X_val_20d, y_val_20d, X_test_20d, y_test_20d = preprocess_data(\n",
    "        train_data, val_data, test_data, '20D_Up', continuous_features, binary_features)\n",
    "    \n",
    "    print(\"\\nTraining 20D MLP model with 5-fold TimeSeriesSplit CV...\")\n",
    "    \n",
    "    best_cv_score_20d = float('inf')\n",
    "    best_config_20d = None\n",
    "    best_model_20d = None\n",
    "    \n",
    "    # 5-fold cross-validation for hyperparameter selection\n",
    "    for i, config in enumerate(configs):\n",
    "        print(f\"\\nConfiguration {i+1}/{len(configs)}: {config}\")\n",
    "        \n",
    "        cv_scores = []\n",
    "        \n",
    "        # 5-fold TimeSeriesSplit cross-validation\n",
    "        for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train_20d)):\n",
    "            print(f\"  Fold {fold + 1}/5\")\n",
    "            \n",
    "            # Split data for this fold\n",
    "            X_train_fold = X_train_20d[train_idx]\n",
    "            X_val_fold = X_train_20d[val_idx]  # CV validation\n",
    "            y_train_fold = y_train_20d.iloc[train_idx]\n",
    "            y_val_fold = y_train_20d.iloc[val_idx]\n",
    "            \n",
    "            # Create datasets\n",
    "            train_dataset = MLPDataset(X_train_fold, y_train_fold.values, seed=42)\n",
    "            val_dataset = MLPDataset(X_val_fold, y_val_fold.values, seed=42)\n",
    "            \n",
    "            generator = torch.Generator()\n",
    "            generator.manual_seed(42 + fold)\n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, generator=generator)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "            \n",
    "            # Create model\n",
    "            torch.manual_seed(42 + i * 10 + fold)\n",
    "            model = MLPModel(X_train_20d.shape[1], config['hidden_sizes'], config['dropout']).to(device)\n",
    "            \n",
    "            # Train model\n",
    "            train_losses, val_losses, epochs_trained = train_model(\n",
    "                model, train_loader, val_loader, lr=config['lr'], patience=15, seed=42 + i * 10 + fold\n",
    "            )\n",
    "            \n",
    "            # Record fold validation loss\n",
    "            fold_val_loss = val_losses[-1]\n",
    "            cv_scores.append(fold_val_loss)\n",
    "            print(f\"    Fold {fold + 1} validation loss: {fold_val_loss:.4f}\")\n",
    "        \n",
    "        # Calculate average CV score\n",
    "        mean_cv_score = np.mean(cv_scores)\n",
    "        std_cv_score = np.std(cv_scores)\n",
    "        print(f\"  Average CV Score: {mean_cv_score:.4f} ± {std_cv_score:.4f}\")\n",
    "        \n",
    "        # If this configuration is better, retrain on full training set\n",
    "        if mean_cv_score < best_cv_score_20d:\n",
    "            best_cv_score_20d = mean_cv_score\n",
    "            best_config_20d = config\n",
    "            \n",
    "            print(f\"  New best config! Retraining on full training set...\")\n",
    "            \n",
    "            # Retrain best model on full training set (early stopping on separate validation set)\n",
    "            train_dataset_full = MLPDataset(X_train_20d, y_train_20d.values, seed=42)\n",
    "            val_dataset_full = MLPDataset(X_val_20d, y_val_20d.values, seed=42)  # Separate validation set for early stopping\n",
    "            \n",
    "            generator_full = torch.Generator()\n",
    "            generator_full.manual_seed(42)\n",
    "            \n",
    "            train_loader_full = DataLoader(train_dataset_full, batch_size=32, shuffle=True, generator=generator_full)\n",
    "            val_loader_full = DataLoader(val_dataset_full, batch_size=32, shuffle=False)\n",
    "            \n",
    "            torch.manual_seed(42 + i)\n",
    "            best_model_20d = MLPModel(X_train_20d.shape[1], config['hidden_sizes'], config['dropout']).to(device)\n",
    "            \n",
    "            # Train with early stopping on separate validation set\n",
    "            train_losses, val_losses, epochs_trained = train_model(\n",
    "                best_model_20d, train_loader_full, val_loader_full, lr=config['lr'], patience=15, seed=42 + i\n",
    "            )\n",
    "    \n",
    "    print(f\"\\nBest configuration for 20D model: {best_config_20d}\")\n",
    "    print(f\"Best CV score: {best_cv_score_20d:.4f}\")\n",
    "    \n",
    "    # Evaluate 20D model on test set\n",
    "    test_dataset_20d = MLPDataset(X_test_20d, y_test_20d.values)\n",
    "    test_loader_20d = DataLoader(test_dataset_20d, batch_size=32, shuffle=False)\n",
    "    \n",
    "    y_pred_20d, y_prob_20d = predict_model(best_model_20d, test_loader_20d)\n",
    "    results_20d = evaluate_model(y_test_20d, y_pred_20d, y_prob_20d, \"20D_Up Prediction\")\n",
    "    \n",
    "    # Generate SHAP analysis for 20D model\n",
    "    shap_values_20d = generate_shap_analysis(best_model_20d, X_test_20d, feature_names, \"20D_Up Prediction\")\n",
    "    \n",
    "    # Model performance summary\n",
    "    print(f\"\\nModel Performance Summary:\")\n",
    "    print(f\"1D Model - AUC: {results_1d['auc']:.4f}, F1: {results_1d['f1_macro']:.4f}\")\n",
    "    print(f\"20D Model - AUC: {results_20d['auc']:.4f}, F1: {results_20d['f1_macro']:.4f}\")\n",
    "    print(f\"1D Best Config: {best_config_1d}\")\n",
    "    print(f\"20D Best Config: {best_config_20d}\")\n",
    "    print(f\"1D Best CV Score: {best_cv_score_1d:.4f}\")\n",
    "    print(f\"20D Best CV Score: {best_cv_score_20d:.4f}\")\n",
    "    \n",
    "    return results_1d, results_20d, best_model_1d, best_model_20d\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('DATA.csv')\n",
    "\n",
    "# Version 1: Baseline Model\n",
    "continuous_features_base = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct', 'J', \n",
    "                           'mfi', 'MACD', 'MACD_diff', 'BB_rel_pos', 'Vol_Change']\n",
    "binary_features_base = ['MA5_GT_MA20']\n",
    "\n",
    "print(\"\\nVERSION 1: Baseline Model (Technical Indicators Only)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "results_baseline = run_mlp_model(df, continuous_features_base, binary_features_base, \n",
    "                                \"Baseline\", \"Baseline\")\n",
    "\n",
    "# Version 2: Interest Rate Model\n",
    "continuous_features_ir = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct', 'J', \n",
    "                          'mfi', 'MACD', 'MACD_diff', 'BB_rel_pos', 'Vol_Change', 'Interest_Rate']\n",
    "\n",
    "print(\"\\nVERSION 2: Interest Rate Model\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "results_ir = run_mlp_model(df, continuous_features_ir, binary_features_base, \n",
    "                          \"with Interest Rate\", \"with Interest Rate\")\n",
    "\n",
    "# Version 3: Bitcoin Model\n",
    "continuous_features_btc = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct', 'J', \n",
    "                          'mfi', 'MACD', 'MACD_diff', 'BB_rel_pos', 'Vol_Change', 'Bitcoin_Close']\n",
    "\n",
    "print(\"\\nVERSION 3: Bitcoin Model\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "results_btc = run_mlp_model(df, continuous_features_btc, binary_features_base, \n",
    "                          \"with Bitcoin\", \"with Bitcoin\")\n",
    "\n",
    "\n",
    "# Version 4: Gold Model\n",
    "continuous_features_gold = ['1D_PastChangePct', '5D_PastChangePct', '20D_PastChangePct', 'J', \n",
    "                          'mfi', 'MACD', 'MACD_diff', 'BB_rel_pos', 'Vol_Change', 'Gold_Close']\n",
    "\n",
    "print(\"\\nVERSION 4: Gold Model\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "results_gold = run_mlp_model(df, continuous_features_gold, binary_features_base, \n",
    "                          \"with Gold\", \"with Gold\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL MODEL VERSIONS COMPLETED!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Summary of all model performances:\")\n",
    "print(f\"Baseline Model     - 1D AUC: {results_baseline[0]['auc']:.4f}, 20D AUC: {results_baseline[1]['auc']:.4f}\")\n",
    "print(f\"Interest Rate Model - 1D AUC: {results_ir[0]['auc']:.4f}, 20D AUC: {results_ir[1]['auc']:.4f}\")\n",
    "print(f\"Bitcoin Model      - 1D AUC: {results_btc[0]['auc']:.4f}, 20D AUC: {results_btc[1]['auc']:.4f}\")\n",
    "print(f\"Gold Model         - 1D AUC: {results_gold[0]['auc']:.4f}, 20D AUC: {results_gold[1]['auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa14b3f9-e7da-4ee3-a0c0-c8dcd9814e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8ddb82-e232-48f8-935d-7bc2654662f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5336342-9ca0-4b91-b1a3-809e79237af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b5567e-48e9-4d5e-9cc4-e83587e58972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
